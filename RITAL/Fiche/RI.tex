\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, margin=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage[french]{babel}

\usepackage[default,scale=0.95]{opensans}
\usepackage[T1]{fontenc}
\usepackage{amssymb} %math
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{systeme}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    % pdfpagemode=FullScreen,
    }
\urlstyle{same} %\href{url}{Text}

\theoremstyle{plain}% default
\newtheorem{thm}{Théorème}[section]
\newtheorem{lem}[thm]{Lemme}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollaire}
%\newtheorem*{KL}{Klein’s Lemma}

\theoremstyle{definition}
\newtheorem{defn}{Définition}[section]
\newtheorem{exmp}{Exemple}[section]
% \newtheorem{xca}[exmp]{Exercise}

\theoremstyle{remark}
\newtheorem*{rem}{Remarque}
\newtheorem*{note}{Note}
%\newtheorem{case}{Case}

\graphicspath{{./RI/}}

\title{Fiche RI}
\author{Charles Vin}
\date{2023}

\begin{document}
\maketitle

\section{Généralité}
\begin{itemize}
    \item RI ad-hoc : c'est ce qu'on fait : trouver parmi un ensemble d'articles ceux qui concernent un sujet spécifique.
    \item Indexation = encodage des documents avec un modèle RI
    \item Deux types d'index \begin{itemize}
        \item Index normal : Document : (terme, nombre/score)
        \item Index inversé : Mot : (document, nombre/score)
    \end{itemize}
    \item Requete sur index : on somme les scores pour obtenir le score final d'un document
    \item Stemming : ne garde que la racine des mots, un peu moche 
    \item Lematization : retour vers un mot complet
    \item Strategie de recherche : \begin{itemize}
        \item Problème : On a beaucoup de doc, on cherche les K premiers
        \item Deux strat  pour index inversé : \begin{itemize}
            \item TAAT : traiter les terme un par un, fonctionne bien sur des petits corpus où il y a une grande différence de score \begin{enumerate}
                \item Trier l'index de chaque terme par score croissant -> une grosse liste ordonnée terme puis score 
                \item Parcourir par terme et maintenir un dictionnaire avec les scores par document, optimisation : utilisation d'une Heap
            \end{enumerate}
            \item DAAT : traiter les doc un par un, plus efficace pour les grandes collections, plus 
        \end{itemize}
    \end{itemize}
\end{itemize}



\section{Loi de Zipf}
Stipule que la fréquence d'occurrence d'un mot est inversement proportionnelle à celle de son rang. Le 1er mot est environ 2 fois plus fréquent que le 2nd qui est 2 fois plus fréquent que le 3e etc.. 
\[
    \frac{ \frac{1 }{r^s}}{ \sum_{n=1}^{N} \frac{1}{N}} \approx \frac{1}{r^s}
.\]
Avec $ r $ le rang, $ N $ la taille du corpus et $ s $ un paramètre spécifique au corpus

\section{Loi de Heaps}
Lien entre le nombre de mots distinct et le nombre de mots : \begin{itemize}
    \item les nouveaux mots apparaissent moins fréquenmment quand le vocabulaire croît. 
    \item La taille du vocabulaire n'a pas de borne supérieure (nom propres, erreur de typo)
\end{itemize} 
\[
    V = K n ^\beta 
.\]
Avec $ V $ taille du vocabulaire, $ N $ taille du texte, $ K, \beta  $ paramètre spécifique du texte.

\section{TF-IDF}
\begin{itemize}
    \item Term Frequency : Une pondération locale, fréquence du terme dans le document $ \frac{f_{t,d}}{\sum_{t' \in d}^{} f_{t', d}} $ 
    \item Inverse Document frequency : Une pondération globale, fréquence inverse décroit vers 0 si le terme apparait dans tous les documents $ \log_{} \frac{N}{df(t_i)} $ avec $ df $ nombre de documents contenant le terme, $ N $ nombre de document. 
    \item TF-IDF : $ tf * idf $, il existe plein de variance. En particulier en TD on a fait un "count idf" : $ f_{t,d} \log_{} \frac{N}{n_t}, n_t = $ nombre de document où $ t $ est présent.
\end{itemize}


\section{Modèle booléen}
formule logique into score binaire, pas de pondération rien
\section{Modèle vectoriel}
Score de distance entre deux vecteurs : un de document score (classiquement un tf) et celui de la requète (classiquement binaire par terme). Inner product $ <X,Y> $, cosinus $ \frac{<X,Y>}{\left\| X \right\| \left\| Y \right\| } $ 

\section{Modèle probabiliste}
Soit $ R $ une v.a.r binaire pour un dociment $ d $ est pertinent pour la question $ q $. 
\begin{itemize}
    \item On cherche la proba $ P(R | q,d) $ que le document soit pertinent pour la question et le document.
    \item Par bayes on tombe sur $ P(d | R, q) P(R | q ) $.
    \item Un document se décompose en terme \textbf{indépendant} de cette manière  $d : (\bigwedge_{t \in d} ) \wedge (\bigwedge_{t \not \in d} t \not \in d)$
    \item $ \prod_{t \in d}^{} P(t \in d | R, q) \prod_{t \not\in d} P(t \not \in d | R, q) P( R | q) $
    \item Et on peut estimer la proba qu'un terme apparaisse dans un document pertinent $ p_t = P(t \in d | R, q), 1 - p_t = P(t \not\in d | R, q) $. 
    \item Finalement on peut développer un peu avec un tricks sur le produit et virer les constantes\begin{align*}
        P(R | d,q) &= P(R|q) \prod_{t \in d} p_t \prod_{t \not\in d} 1 - p_t \\
                &= P(R | q) \prod_{t \in d}^{} p_t \frac{1}{1 - p_t} \prod_{t \in \mathcal{T}}^{} 1 - p_t \\ 
                &\propto \prod_{t \in d}^{} p_t \frac{1}{1 - p_t}
    \end{align*}
    \item De base le model pose $ \frac{P(R | q, d)}{P(\not R | q, d)} $, même développement qu'au dessus, puis passage au log pour obtenir un score 
    \[
        s(q,d) = \sum_{t \in q \sqcap d}^{} \log \frac{p_t (1 - u_t)}{u_t (1 - p_t)}
    .\]
    En pratique : $ s(q,d) = \sum_{t \in q \sqcap d}^{} \log_{} \frac{a + 0.5}{c + O.5} \frac{d + 0.5}{b+0.5} $ avec $a=$nb appartition terme dans doc pertinent, $b$ nb apparition terme dans document non pertinent, $c$ nb de \textbf{non} apparitition dans document pertinent et $d$ nb \textbf{non} apparition terme dans document non pertinenet
    \begin{table}[!ht]
        \centering
        \begin{tabular}{|l|l|l|}
        \hline
            ~ & Doc Pertinent & Non Pertinent \\ \hline
            $t \in d$ & a & b \\ \hline
            $t \not\in d$ & c & d \\ \hline
        \end{tabular}
    \end{table}
    \item On estime les proba par max vraissemblance qui donne juste la fréquence des termes
    \item On peut intégré un prior sur $ P(d) $ mais je sais honnetement pas à quelle étape : longueur du doc, longueur moyenne des mots, date, nombre de lien, pagerank
\end{itemize}

\subsection{BM25/Okapi}
Si $ t \not\in d \Leftrightarrow TF_t = 0 $ puis avec une modelisation de poisson sur la valeur de ce terme, on retombe sur la formule du coef BM25. Woah qu'est ce que c'est que ce trucs c'est le futur à estimer les param de la poisson

\section{Modèle de langue }
Basé sur l'idée que pour faire une recherche on imagine les mots que le documents pertinent vas contenir. Quel est la proba que le document soit généré par le même modèle de langue que le document.

\[
    p(t_1, \dots, t_n) = \sum_{t}^{}tf(t)\log_{} P(t | \theta _{Md}) = \sum_{t}^{}tf(t)\log_{} p_t
.\]
Par max vraissemblance + langragien  $ p_t = \frac{tf_(t)}{\sum_{t}^{}tf(t)} $ . C'est très très flou dans le diapo.

Dans le cas où un mot de la requête n'apparrait pas dans le document, score = 0 $\rightarrow$ Lissage des probas = modèle de
mélange multinomial entre la distribution des termes dans le
document et la distribution des termes dans la collection = Dirichlet ou Jelinek-Mercer

\section{Reformulation de requete}
\subsection{Revelance feedback}
Recalculer les poids des document en fonction du feedback des users et recalculer des nouveaux score. Modèle de Rocchio pour les modèles vectoriel \begin{itemize}
    \item Par le retour de l'utilisateur, deux ensembles de vecteur de document : les documents pertinent VS les non pertinents
    \item Vecteur moyen des documents pertinent $\rightarrow$ Correction de notre vecteur de question 
    \[
        q_{new} = a q_{old} + b * d^+ - c d^-
    .\]
    avec $ d^+ $ le vecteur moyen des documents pertinents, same pour $ d^- $. Puis binariser q avec un seuil
\end{itemize}
Limite : 
\begin{itemize}
    \item Fiabilité des users sur les retours positif négatif 
    \item Comment ils évalue la pertinence
    \item Mais on garde un effet de masse qui moyenne les erreurs 
\end{itemize}

\subsection{Pseudo revelance feedback}
Sugestion d'une nouvelle requete en se basant sur les $ k $ premier document. Pour la trouver méthode de clustering, similarité des termes, ...

Limite : 
\begin{itemize}
    \item Couteux
    \item Query drift : si les top documents ne sont pas pertinents, la requete reformulée ne reflètera jamais le besoin de l'utilisateur (exemple : Apple et apple :  on vas biaiser la requete vers un seul des deux sens)
\end{itemize}

\section{Métrique}
\subsection{Métrique orientées rappel/précision}
Précision et rappel
\begin{itemize}
    \item Recall : Pourcentage de documents pertinents renvoyés parmi tous ceux qui sont pertinents. Utilisé quand les faux négatifs sont couteux (exemple : le médical, documentaliste).
    \[
        \frac{\left\| R \cap P \right\| }{\left\| P \right\| }
    .\]
    Avec $ R $ l'ensemble des documents renvoyés et $ P $ les documents pertinents. 

    \item Précision : Pourcentable de documents pertinents renvoyés parmis ceux renvoyés. Utilisé quand les faux positif sont couteux (exemple : la RI : moteur de recherche).
    \[
        \frac{\left\| R \cap P \right\| }{\left\| R \right\| }
    .\]
    Avec $ R $ l'ensemble des documents renvoyés et $ P $ les documents pertinents.

    \item C'est un compromi, augmenter l'un fait baisser l'autre
    \item F-mesure 
    \[
        F_\beta = (1 + \beta ^2) \frac{P * R}{\beta ^2 (P+R)}
    .\]

    \item Tracer une courbe précision recall : \begin{enumerate}
        \item faire un tableau avec pour colonne : rang, (probabilité), y true, recall, precision.
        \item Calculer le recal et la précision pour chaque ligne en rajoutant les résultats d'avant
        \item Puis pour tracer la courbe : chaque ligne = un point du graph
    \end{enumerate}
    
    \item Précision interpolée : super visuel, pour tracer la courbe, on fait varier le recall, pour chaque point on regarde la précision max à droite de ce point. Soit $ r $  un point de recall, $ P_{interp}(r) = \max _{r' \geq r} P(r') $ 
    
    \item Précision moyenne : moyenne arithmétique de la précision interpolé \\
    OU $ \approx \text{AveP} = \frac{\sum_{k=1}^n P(k) \times {1}_{doc_k \text{ is revelant}}} {\text{total number of relevant documents}}$ 
    \item \textbf{Moyenne des précision moyenne (MAP)} = moyenne des précision moyenne pour chaque requette
    
\end{itemize}
\begin{figure}[!htbp]
    \centering
    \includegraphics*[width=.5\textwidth]{precision_recall_conf_matrix.png}
    \caption{En rouge la précision, en jaune le rappel}
    \label{fig:precision_recall}
\end{figure}

\subsection{Métrique orientées rang}
\begin{itemize}
    \item \textbf{Moyenne des rangs inverse (MRR)} : moyenne de l'inverse du rang du premier document pertinent renvoyé sur l'ensemble des requêtes $ \frac{1}{\left| Q \right| } \sum_{q \in Q}^{} \frac{1}{rank_i} $ where $ \text{rank}_{i}$ refers to the rank position of the first relevant document for the i-th query.
    
    \item \textbf{Discounted cumulative gain (DCG)} :  Somme pondéré par $ \frac{1}{\log_{2} (rang)} $ du score de pertinence des documents. $ DCG_p = score_1 + \sum_{i=1}^{p} \frac{score_i}{\log_{2} i} $ pour une requète. 
    \item Normlized DCG : pour pouvoir faire une moyenne sur l'ensemble des requète il faut normaliser le DCG en utilisant le IDCG (liste idéale de résultat) $ nDCG_p = \frac{DCG_p}{IDCG_p} $ 
\end{itemize}

\section{Apprentissage de model}
\begin{itemize}
    \item Distillation : Faire apprendre un premier modèle moins gourmand en ressource, qui fera beaucoup de faux négatif, puis entrainer un autre modèle par dessus ces prédictions $\rightarrow$ plus robuste au bruit car il est pas directement exposé au faux negatif. Très efficace
\end{itemize}
\subsection{Modèle dense / de représentation}
\begin{itemize}
    \item Représenter la query et l'input dans un espace latent (le même ou non) de même taille puis score de similarité (cos ou autre)
    \item \textbf{Gros overfit} car augmenter le score $ \Leftrightarrow $ augmenter la norme et espace assez grand pour overfit chaque doc
    \item \textbf{forward lent}
    \item Technique de clusterisation : \begin{itemize}
        \item Pour eviter l'overfit pendant l'apprentisage batch uniquement du même cluster
        \item Pour faire moins de produit scalaire car couteux, produit scalaire avec représentatn des clusters
    \end{itemize}
\end{itemize}

\subsection{Modèle d'intération}
\begin{itemize}
    \item Intération faible : matrice pour faire la similarité into NN score (marchait pas beaucoup)
    \item Intéraction forte : concaténation de la query et du doc into NN score (cross encoder)
    \item Cross Encoder : Transformer + input concat query doc $\rightarrow$ Classifier linéaire sur la sortie en grande dimension $\rightarrow$ score ; gourmand mais performant 
    \item Mécanisme en deux temps : gros tri avec un pré-traitement, et ordonancement avec le modèle d'interaction forte
\end{itemize}
\subsection{Modèle sparce}
\begin{itemize}
    \item Rien compris
    \item Doc2query : Doc $\rightarrow$ Question sur le doc $\rightarrow$ concaténation de la question et du doc $\rightarrow$ amélioration des performances de recherche !
    \item CCL:  Bon résultat, mieux que BM25, robuste ; un peu lourd à apprendre ; pour arriver à l'état de l'art il faut quand même ajouter un cross encoder en 2ème étape
\end{itemize}

\section{Page Rank}
\begin{itemize}
    \item Analyse les liens entre les pages, graph orienté de page
    \item On veut trouver la distribution stationnaire $ s $ du graph (comme dans markov chain)
    \item $ A $ matrice d'ajascence avec $ a_{ij} = 1$ si lien de $ i $ ver $ j $, $ d_i = \sum_{j}^{} a_{ij} $ nombre de lien entrant pour une page, $ P $ matrice de transition avec $ p_{ij} = \frac{a_{ij}}{d_i}$ proba de transition de $ j $ à $ i $ 
    \item $ s_j = d \sum_{i}^{}p_{ij} s_i + (1 - d) a_j, d$ facteur d'armotissement ($ \approx 0.8 $ )
    \item $ s = dsP + (1-d)a $ 
\end{itemize}

\end{document}