{"cells":[{"cell_type":"markdown","metadata":{"id":"LH8RegM9pN43"},"source":["# Exercice de synthèse\n","\n","On s'intéresse ici à résoudre la tâche de [TREC CAST](http://www.treccast.ai/) qui modélise une session de recherche conversationnelle : \n","\n","- l'utilisateur pose des questions à un système de dialogue\n","- le système de dialogue lui répond\n","- on peut imagine que le système de dialogue est associé à un moteur de recherche et pour chaque question soumet une requête au système de RI pour trouver des documents.\n","\n","La tâche traitée ici est d'ordonnancer des documents à un instant *t* compte tenu de l'historique des requêtes. Plusieurs stratégies peuvent être mises en place (pouvant être cumulées ou pas selon vos envies) : \n","\n","- Construire un vecteur de contexte\n","- Reformuler les requêtes en fonction du contexte (historique ou vecteur)\n","- Sélectionner dans l'historique les éléments importants\n","- Ordonnancement global avec prise en compte du contexte\n","- ...\n","\n","L'objectif ici est de mettre en place plusieurs modèles de votre choix, les comparer. Vous avez le droit : \n","- d'utiliser des techniques vues dans les cours précédents de l'école d'été\n","- d'utiliser des datasets externes. \n","\n","\n","Vous pouvez vous mettre en groupe pour discuter. C'est autant un travail d'implémentation que de recherche pour trouver quelle modélisation serait pertinente (et comme tout travail de recherche, je n'ai pas la réponse absolue ! ;) )\n","\n","A vous de jouer !"]},{"cell_type":"markdown","metadata":{"id":"0VZQb0Ocrf13"},"source":["## Jeux de données\n","\n","Le challenge est composé des données suivantes : \n","- jeu de données MSMarco dont l'index est stocké [ici](https://drive.google.com/drive/folders/1q1djRDCGkGBojcEBjToEF2s_VH9jAAXB?usp=sharing)\n","- les requêtes et les jugements de pertinence sont disponibles [ici](https://github.com/daltonj/treccastweb/blob/master/2019/) \n","\n","Le format des fichiers (requêtes et jugements de pertinence) est celui de TREC : \n","- Pour les requêtes : on retrouve l'identifiant des requêtes et le texte associé. A noter, les requêtes sont sous le format x_y : x pour l'identifiant de la session et y pour l'itération de la session. Cela permet de modéliser la séquence de requêtes au sein d'une session (et donc l'historique).\n","```\n","<query>\n","<number>1_1</number>\n","<text>#combine(physician assistant )</text>\n","</query>\n","```\n","\n","\n","\n","- Pour les jugements de pertinence : id requête, 0, id document précédé de la collection (e.g. : MARCO_ à enlever), niveau de pertinence.\n","\n","\n","```\n","1_1 0 MARCO_955948 2\n","1_1 0 MARCO_6203672 2\n","1_1 0 MARCO_849267 0\n","1_1 0 MARCO_2331424 0\n","```\n","\n","\n","\n","**Note importante** : les jugements de pertinence ont des préfixes différents faisant référence à différents jeux de données (MSMARCO, CAR, ...). C'est lié au fait que la tâche TREC CAST repose sur plusieurs index de documents. Pour faire simple, on ne considère ici que MSMARCO, donc ne prendre en compte que les jugements de pertinence qui lui sont associés."]},{"cell_type":"markdown","metadata":{"id":"XCne56tt0a3N"},"source":["Pour charger des données depuis google drive :"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26331,"status":"ok","timestamp":1623848751635,"user":{"displayName":"Lau re","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzuUia-j0jYugKgvO36IkfRFcUwM6qoXOYimquhg=s64","userId":"03302099944040145915"},"user_tz":-120},"id":"1yJmtaYUwfPn","outputId":"3c0e5150-42f1-4996-8a6c-8ee77c5d4751"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kBvFCRaUuquf"},"outputs":[{"ename":"AttributeError","evalue":"module 'pyterrier' has no attribute 'get_dataset'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyterrier\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39;49mget_dataset(\u001b[39m'\u001b[39m\u001b[39mirds:msmarco-passage\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m#récupération de l'index déja créé\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# if index exists\u001b[39;00m\n\u001b[1;32m      7\u001b[0m indexref \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mIndexRef\u001b[39m.\u001b[39mof(\u001b[39m\"\u001b[39m\u001b[39m/content/drive/MyDrive/etal2021/passage_index/data.properties\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: module 'pyterrier' has no attribute 'get_dataset'"]}],"source":["import pyterrier as pt\n","\n","dataset = pt.get_dataset('irds:msmarco-passage')\n","\n","#récupération de l'index déja créé\n","# if index exists\n","indexref = pt.IndexRef.of(\"/content/drive/MyDrive/etal2021/passage_index/data.properties\")\n","# print(indexref.toString())\n","index = pt.IndexFactory.of(indexref)\n","print(index.getCollectionStatistics().toString())"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["msmarco-passage documents:   0%|          | 0/8841823 [00:00<?, ?it/s]/tmp/ipykernel_38126/1517213811.py:12: DeprecationWarning: specifying meta and meta_lengths in IterDictIndexer.index() is deprecated, use constructor instead\n","  index_ref = indexer.index(msmarco.get_corpus_iter(),\n","[INFO] Please confirm you agree to the MSMARCO data usage agreement found at <http://www.msmarco.org/dataset.aspx>\n","[INFO] If you have a local copy of https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz, you can symlink it here to avoid downloading it again: /home/charles/.ir_datasets/downloads/31644046b18952c1386cd4564ba2ae69\n","[INFO] [starting] https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz\n","                                                                      \n","\u001b[A                                                                                                                          [INFO] [finished] https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz: [05:36] [1.06GB] [3.14MB/s]\n","[INFO] [starting] fixing encoding                                     \n","                                                                      \n","\u001b[A                                      [INFO] [finished] fixing encoding: [08:32] [3.06GB] [5.98MB/s]\n","msmarco-passage documents:   0%|          | 0/8841823 [14:09<?, ?it/s]Exception in thread Thread-5 (_write_fifos):\n","Traceback (most recent call last):\n","  File \"/home/charles/.pyenv/versions/3.10.10/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/home/charles/.pyenv/versions/3.10.10/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/home/charles/.pyenv/versions/3.10.10/lib/python3.10/site-packages/pyterrier/index.py\", line 991, in _write_fifos\n","    for doc in it:\n","  File \"/home/charles/.pyenv/versions/3.10.10/lib/python3.10/site-packages/pyterrier/index.py\", line 830, in <genexpr>\n","    return ({f: doc[f] for f in all_fields} for doc in it)\n","  File \"/home/charles/.pyenv/versions/3.10.10/lib/python3.10/site-packages/pyterrier/index.py\", line 830, in <dictcomp>\n","    return ({f: doc[f] for f in all_fields} for doc in it)\n","KeyError: 'abstract'\n","msmarco-passage documents:   0%|          | 0/8841823 [14:10<?, ?it/s]\n"]},{"ename":"JavaException","evalue":"JVM exception occurred: No IndexLoaders were supported for indexref ./msmarco-passage/data.properties; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref? java.lang.UnsupportedOperationException","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJavaException\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[39m# dans le cas où l'index existe déjà\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     index_ref \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mIndexRef\u001b[39m.\u001b[39mof(pt_index_path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/data.properties\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m index \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39;49mIndexFactory\u001b[39m.\u001b[39;49mof(index_ref)\n","File \u001b[0;32mjnius/jnius_export_class.pxi:1177\u001b[0m, in \u001b[0;36mjnius.JavaMultipleMethod.__call__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mjnius/jnius_export_class.pxi:884\u001b[0m, in \u001b[0;36mjnius.JavaMethod.__call__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mjnius/jnius_export_class.pxi:1056\u001b[0m, in \u001b[0;36mjnius.JavaMethod.call_staticmethod\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mjnius/jnius_utils.pxi:91\u001b[0m, in \u001b[0;36mjnius.check_exception\u001b[0;34m()\u001b[0m\n","\u001b[0;31mJavaException\u001b[0m: JVM exception occurred: No IndexLoaders were supported for indexref ./msmarco-passage/data.properties; It may be your ref has the wrong location. Alternatively, Terrier is misconfigured - did you import the correct package to deal with this indexref? java.lang.UnsupportedOperationException"]}],"source":["import os\n","\n","msmarco = pt.datasets.get_dataset('irds:msmarco-passage')\n","pt_index_path = './msmarco-passage'\n","\n","if not os.path.exists(pt_index_path + \"/data.properties\"):\n","    # création de l'index. Utilisation de l'itérateur pour parcourir la collection\n","    indexer = pt.index.IterDictIndexer(pt_index_path)\n","\n","    # on donne à l'index la fonction pour parcourir l'index avec l'itérateur  get_corpus_iter()\n","    # On spécifie les champs à indexer et les meta-données à sauvegarder\n","    index_ref = indexer.index(msmarco.get_corpus_iter(),\n","                                fields=('abstract',),\n","                                meta=('docno',))\n","else:\n","    # dans le cas où l'index existe déjà\n","    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n","index = pt.IndexFactory.of(index_ref)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNPSuszXdKuSIswBKHs4hID","name":"Exercice de synthèse.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
