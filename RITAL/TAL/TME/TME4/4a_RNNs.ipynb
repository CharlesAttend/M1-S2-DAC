{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlesAttend/M1-S2-DAC/blob/main/RITAL/TAL/TME/TME4/4a_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c3d011d",
      "metadata": {
        "id": "4c3d011d"
      },
      "source": [
        "## --- Generate text with a recurrent neural network (Pytorch) ---\n",
        "### (Mostly Read & Run)\n",
        "\n",
        "The goal is to replicate the (famous) experiment from [Karpathy's blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
        "\n",
        "To learn to generate text, we train a recurrent neural network to do the following task:\n",
        "\n",
        "Given a \"chunk\" of text: `this is random text`\n",
        "\n",
        "the goal of the network is to predict each character in **`his is random text` ** sequentially given the following sequential input **`this is random tex`**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "905e7491",
      "metadata": {
        "id": "905e7491"
      },
      "source": [
        "Input ->  Output\n",
        "--------------\n",
        "T    ->    H\n",
        "H    ->    I\n",
        "I    ->    S\n",
        "S    ->    \" \"\n",
        "\" \"  ->    I\n",
        "I    ->    S\n",
        "S    ->    \" \"\n",
        "[...]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7adb3f04",
      "metadata": {
        "id": "7adb3f04"
      },
      "source": [
        "\n",
        "## Load text (dataset/input.txt)\n",
        "\n",
        "Before building training batch, we load the full text in RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b8d03d20",
      "metadata": {
        "id": "b8d03d20",
        "outputId": "e8d5ed1d-1279-432b-bc04-5e002f601d35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-17 16:01:28--  https://thome.isir.upmc.fr/classes/RITAL/input.txt\n",
            "Resolving thome.isir.upmc.fr (thome.isir.upmc.fr)... 134.157.18.247\n",
            "Connecting to thome.isir.upmc.fr (thome.isir.upmc.fr)|134.157.18.247|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  1.55MB/s    in 0.7s    \n",
            "\n",
            "2023-02-17 16:01:30 (1.55 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://thome.isir.upmc.fr/classes/RITAL/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1fa52e79",
      "metadata": {
        "id": "1fa52e79",
        "outputId": "9b4cd2d2-5c42-425b-dc1e-79b19730f1c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ],
      "source": [
        "! pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "890c249b",
      "metadata": {
        "id": "890c249b",
        "outputId": "38b001f5-1ba5-4715-8d75-eadab7c4130d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_len = 1115394\n"
          ]
        }
      ],
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "file = unidecode.unidecode(open('./input.txt').read()) #clean text => only ascii\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af54275",
      "metadata": {
        "id": "4af54275"
      },
      "source": [
        "## 2: Helper functions:\n",
        "\n",
        "We have a text and we want to feed batch of chunks to a neural network:\n",
        "\n",
        "one chunk  A,B,C,D,E\n",
        "[input] A,B,C,D -> B,C,D,E [output]\n",
        "\n",
        "Note: we will use an embedding layer instead of a one-hot encoding scheme.\n",
        "\n",
        "for this, we have 3 functions:\n",
        "\n",
        "- One to get a random str chunk of size `chunk_len` : `random_chunk` \n",
        "- One to turn a chunk into a tensor of size `(1,chunk_len)` coding for each characters : `char_tensor`\n",
        "- One to return random input and output chunks of size `(batch_size,chunk_len)` : `random_training_set`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e1f68d51",
      "metadata": {
        "id": "e1f68d51",
        "outputId": "a8c799b8-2c92-4544-d0b2-18d029abdb7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[12, 30, 27, 29, 28, 34, 96, 32, 18, 29],\n",
            "        [21, 18, 15, 14, 94, 13, 18, 13, 94, 21],\n",
            "        [94, 17, 24, 21, 34, 94, 43, 10, 27, 27],\n",
            "        [14, 94, 24, 15, 94, 38, 21, 10, 27, 14]]), tensor([[30, 27, 29, 28, 34, 96, 32, 18, 29, 17],\n",
            "        [18, 15, 14, 94, 13, 18, 13, 94, 21, 24],\n",
            "        [17, 24, 21, 34, 94, 43, 10, 27, 27, 34],\n",
            "        [94, 24, 15, 94, 38, 21, 10, 27, 14, 23]]))\n"
          ]
        }
      ],
      "source": [
        "import time, math\n",
        "\n",
        "\n",
        "#Get a piece of text\n",
        "def random_chunk(chunk_len):\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(1,len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[0,c] = all_characters.index(string[c])\n",
        "    return tensor\n",
        "\n",
        "\n",
        "#Turn a piece of text in train/test\n",
        "def random_training_set(chunk_len=200, batch_size=8):\n",
        "    chunks = [random_chunk(chunk_len) for _ in range(batch_size)]\n",
        "    inp = torch.cat([char_tensor(chunk[:-1]) for chunk in chunks],dim=0)\n",
        "    target = torch.cat([char_tensor(chunk[1:]) for chunk in chunks],dim=0)\n",
        "    \n",
        "    return inp, target\n",
        "\n",
        "print(random_training_set(10,4))  ## should return 8 chunks of 10 letters. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "141dad88",
      "metadata": {
        "id": "141dad88"
      },
      "source": [
        "## The actual RNN model (only thing to complete):\n",
        "\n",
        "It should be composed of three distinct modules:\n",
        "\n",
        "- an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) (n_characters, hidden_size)\n",
        "\n",
        "```\n",
        "nn.Embedding(len_dic,size_vec)\n",
        "```\n",
        "- a [recurrent](https://pytorch.org/docs/stable/nn.html#recurrent-layers) layer (hidden_size, hidden_size)\n",
        "```\n",
        "nn.RNN(in_size,out_size) or nn.GRU() or nn.LSTM() => rnn_cell parameter\n",
        "```\n",
        "- a [prediction](https://pytorch.org/docs/stable/nn.html#linear) layer (hidden_size, output_size)\n",
        "\n",
        "```\n",
        "nn.Linear(in_size,out_size)\n",
        "```\n",
        "=> Complete the `init` function code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8d838e47",
      "metadata": {
        "id": "8d838e47"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as f\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_char, hidden_size, output_size, n_layers=1, rnn_cell=nn.RNN):\n",
        "        \"\"\"\n",
        "        Create the network\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.n_char = n_char\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        #  (batch,chunk_len) -> (batch, chunk_len, hidden_size)  \n",
        "        self.embed = nn.Embedding(n_char, hidden_size)\n",
        "        \n",
        "        # (batch, chunk_len, hidden_size)  -> (batch, chunk_len, hidden_size)  \n",
        "        self.rnn = rnn_cell(hidden_size, hidden_size, num_layers=n_layers)\n",
        "        \n",
        "        #(batch, chunk_len, hidden_size) -> (batch, chunk_len, output_size)  \n",
        "        self.predict = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        batched forward: input is (batch > 1,chunk_len)\n",
        "        \"\"\"\n",
        "        input = self.embed(input)\n",
        "        output,_  = self.rnn(input)\n",
        "        output = self.predict(f.tanh(output))\n",
        "        return output\n",
        "    \n",
        "    def forward_seq(self, input,hidden=None):\n",
        "        \"\"\"\n",
        "        not batched forward: input is  (1,chunk_len)\n",
        "        \"\"\"\n",
        "        input = self.embed(input)\n",
        "        output,hidden  = self.rnn(input.unsqueeze(0),hidden)\n",
        "        output = self.predict(f.tanh(output))\n",
        "        return output,hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34643b32",
      "metadata": {
        "collapsed": true,
        "id": "34643b32"
      },
      "source": [
        "## Text generation function\n",
        "\n",
        "Sample text from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4c751d5f",
      "metadata": {
        "id": "4c751d5f"
      },
      "outputs": [],
      "source": [
        "def generate(model,prime_str='A', predict_len=100, temperature=0.8):\n",
        "    prime_input = char_tensor(prime_str).squeeze(0)\n",
        "    hidden = None\n",
        "    predicted = prime_str+\"\"\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "\n",
        "    for p in range(len(prime_str)-1):\n",
        "        _,hidden = model.forward_seq(prime_input[p].unsqueeze(0),hidden)\n",
        "            \n",
        "    #print(hidden.size())\n",
        "    for p in range(predict_len):\n",
        "        output, hidden = model.forward_seq(prime_input[-1].unsqueeze(0), hidden)\n",
        "                # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        #print(output_dist)\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        #print(top_i)\n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        prime_input = torch.cat([prime_input,char_tensor(predicted_char).squeeze(0)])\n",
        "\n",
        "    return predicted\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8783b21d",
      "metadata": {
        "collapsed": true,
        "id": "8783b21d"
      },
      "source": [
        "## Training loop for net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9acbf3af",
      "metadata": {
        "id": "9acbf3af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475619f8-24b1-4fa2-b48b-1afbbf581cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0m 11s (100 0%) 3.1890]\n",
            "Whonte nfosest m s\n",
            "hapIe npd , t  f t mys rat ce ig t mo, o dle le t trot toloduweAbe,\n",
            " ce t  s  husof \n",
            "\n",
            "[0m 23s (200 1%) 2.8727]\n",
            "Whe  mhe an comorerenn srra t.DHulminsthyhotr  kome th d ce ulre\n",
            "Y oanethon.T thhowocehe ut t t ess am \n",
            "\n",
            "[0m 27s (300 1%) 2.6631]\n",
            "Whe bigo yo s t iy\n",
            "\n",
            "NO\n",
            "Mvone as bafundo w peatI ly batr fe?\n",
            "\n",
            "\n",
            "wad.\n",
            "Acemes meare t t ivis laicus t that \n",
            "\n",
            "[0m 33s (400 2%) 2.7143]\n",
            "Wherep s hanoutheethas thilan sinthtous beenlor t me, s nkeps timethenne;Aqe thas l for ss?\n",
            "Hand at PL \n",
            "\n",
            "[0m 38s (500 2%) 2.5318]\n",
            "Whe nd aioul;\n",
            "Bothewe.\n",
            "ingin ate nd wea, crapnte fre wofanlere her s belord atinl f ad n s,\n",
            "T mle pond \n",
            "\n",
            "[0m 44s (600 3%) 2.5967]\n",
            "Whin fo me fn, ls bl ashour wthile conghestthas wee, by fongsd tt, woml ontar mitere ar? men s, for th \n",
            "\n",
            "[0m 49s (700 3%) 2.5524]\n",
            "Whe. omatheilllll, IO he pouimal me tomesthin, t, s hig taboue t manayOUS:\n",
            "\n",
            "'k my GAB:\n",
            "he t h ss s.\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "[0m 54s (800 4%) 2.6368]\n",
            "Whin re si iransins:\n",
            "Tyoreanst my pe bly,\n",
            "ENTine, tins nd barst, s ouss band somext,\n",
            "Whofor or t be; w \n",
            "\n",
            "[1m 0s (900 4%) 2.5047]\n",
            "Whyof, y y lithe I s icout e; LELI'linome fs he s he the f youe t!\n",
            "Tho the fo f t f f ld s.\n",
            "He, ther b \n",
            "\n",
            "[1m 6s (1000 5%) 2.5415]\n",
            "Why.\n",
            "\n",
            "DURICBotelce ar aten,\n",
            "IConeerul t aner w k woully he'\n",
            "wime the be me ce, I'toure wentee me com h \n",
            "\n",
            "[1m 11s (1100 5%) 2.5589]\n",
            "Wheathallore sthe s gonghat ane is\n",
            "And tore ppl s's bat ma myiscat otote gisenge g n acely thesprd s t \n",
            "\n",
            "[1m 16s (1200 6%) 2.5234]\n",
            "Wheaco te beange guthemalouserse warore hy t t athe dre nkt?\n",
            "\n",
            "F:\n",
            "An lofordlll av'r s fo at o me allert \n",
            "\n",
            "[1m 23s (1300 6%) 2.4971]\n",
            "Whin s'dhe tas us p t an of ningearorp s the,\n",
            "ANLith?\n",
            "ILENEN:\n",
            "G--d athe cak ale,\n",
            "\n",
            "An t t ar conthedit  \n",
            "\n",
            "[1m 28s (1400 7%) 2.5082]\n",
            "Whiowan in ho d ad,\n",
            "And bit ouaver, l VD isthap olesacrtous mo und cre therend:\n",
            "\n",
            "\n",
            "Whirin thas me nda t \n",
            "\n",
            "[1m 33s (1500 7%) 2.5638]\n",
            "Whe s, be h bated anore p; ad and mo s mofis clay,\n",
            "Me shispung, we w,\n",
            "OMOR:\n",
            "\n",
            "\n",
            "I pono ican S:\n",
            "Jom t;\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "[1m 38s (1600 8%) 2.5650]\n",
            "Whe\n",
            "An f cerdoupuust hit allile s:\n",
            "IO:\n",
            "\n",
            "LEThen owicut be weend Y th wheathe t he e t,\n",
            "O:\n",
            "Manemerthe bu \n",
            "\n",
            "[1m 43s (1700 8%) 2.5285]\n",
            "Whe.\n",
            "Whayourwery f st ate wowout se theaco ce t ther.\n",
            "Coupr in hingere\n",
            "NLEDes ouconsthis. sbute t hite \n",
            "\n",
            "[1m 49s (1800 9%) 2.4748]\n",
            "Whart t balld tof thedendrd arart withicergeceelldoureagrat it hin aw, igeaked Poreay t t\n",
            "BURINI tis y \n",
            "\n",
            "[1m 54s (1900 9%) 2.5097]\n",
            "Whar,\n",
            "Dlfer bol f bung he war tho, s d s;\n",
            "\n",
            "Thalely wowher hicalll osill r with Whe kisst y ithadene bo \n",
            "\n",
            "[1m 58s (2000 10%) 2.5307]\n",
            "Whe,\n",
            "\n",
            "ARI an prer br th t yousere wonvere ldenden lyod g an an, blererelthenen y wad bl bundur EERothi \n",
            "\n",
            "[2m 4s (2100 10%) 2.4689]\n",
            "Whee wes my s zeatheake d te s my w tt h be arssthongishorour s thankan mrowe u thenince s omu n? alo  \n",
            "\n",
            "[2m 9s (2200 11%) 2.4906]\n",
            "Whe ou jul ist meresthan velly win blee therand be derigo boraze t bere se he\n",
            "\n",
            "LIUCond befound was me  \n",
            "\n",
            "[2m 15s (2300 11%) 2.4782]\n",
            "Wh the whas omeago'd.\n",
            "\n",
            "\n",
            "\n",
            "Marterd hatsdsto it spoutherd un ureresthar'd be be?\n",
            "\n",
            "ARUS: to wed ie thaso e \n",
            "\n",
            "[2m 19s (2400 12%) 2.5339]\n",
            "Whe t\n",
            "Andore is ofowerssthean ad omene creal the henaid haire shedis ot chishous geswaindr o, pis intr \n",
            "\n",
            "[2m 24s (2500 12%) 2.4950]\n",
            "Wh fothid t mothe he an t ncourt iselltheme nn h po n t lr n s le l arome m.\n",
            "EThay anonanprer, un soro \n",
            "\n",
            "[2m 30s (2600 13%) 2.4873]\n",
            "Whay I te isouth svamyoue I we u s haven momoucees thokeen kist as soour thedthar orence hamared chour \n",
            "\n",
            "[2m 35s (2700 13%) 2.4554]\n",
            "Wharouldo youlowe itie yomis panoulllen cey aderineour y'le fo buth t brer me f.\n",
            "LAndouthind toue bucu \n",
            "\n",
            "[2m 40s (2800 14%) 2.5807]\n",
            "Why RD:\n",
            "Go he perind wthinghad ING gat; ootond ledes ho rs the anerane buthichererenrs id llavell hend \n",
            "\n",
            "[2m 45s (2900 14%) 2.4613]\n",
            "Whisu aryonous s o ghinerd tou s culean ithathe sthake and, p the sint seaiss byofuenathath fu me, t c \n",
            "\n",
            "[2m 50s (3000 15%) 2.4732]\n",
            "Whors te corifares uir ist tu hed thant y whaiche s, I gr t ve wand s.\n",
            "Anis me f lioulle ardorer:\n",
            "Ande \n",
            "\n",
            "[2m 55s (3100 15%) 2.4407]\n",
            "Whayongr s nonn, tik m, latho andour this thaghofar ave t shind m hem fon he l VI'to\n",
            "Thatou hisares me \n",
            "\n",
            "[3m 0s (3200 16%) 2.5272]\n",
            "Whalof the Thy aper me otho'st aint th DUK:\n",
            "Th wand tothe we t thean se 's,\n",
            "TI s t w ame m candule ing \n",
            "\n",
            "[3m 6s (3300 16%) 2.5110]\n",
            "Whe lat w whe ternishine wiof hyoughes.\n",
            "\n",
            "\n",
            "Thinok nor,\n",
            "I pringor n ng fron sinthe th th in S:\n",
            "AUThathth \n",
            "\n",
            "[3m 10s (3400 17%) 2.5009]\n",
            "Why fondean caristrtied teeand ange IAn ango\n",
            "A sthert t fast l avend h e g y t pan ake me p l, gherit. \n",
            "\n",
            "[3m 15s (3500 17%) 2.5054]\n",
            "Whal the apale thmapikt bes' I s ourere there ll se le otoue min be sthe and fod? whanar ank athe me t \n",
            "\n",
            "[3m 21s (3600 18%) 2.4972]\n",
            "Wheeee t he athis were--do be, mee athert wI the tovend the IOnet to walof bon hathad t sthinonconenou \n",
            "\n",
            "[3m 26s (3700 18%) 2.5148]\n",
            "Whe ve r, th t hen t poncou fr toroute touro be aresant:\n",
            "Thout thampe, te my t t bureaveed the wh hath \n",
            "\n",
            "[3m 31s (3800 19%) 2.5111]\n",
            "Whs t ined an CHe by ge ar the isid worivn tamef henglenghe iveno ther hathafan liefororuthastared ish \n",
            "\n",
            "[3m 36s (3900 19%) 2.5059]\n",
            "Whalelld y me f gang thyen'sh trourondow oth hthme I o t ssdy f of o umicowind athe wo chehare othen h \n",
            "\n",
            "[3m 41s (4000 20%) 2.4898]\n",
            "Whyo mou thingle m, were se m hes is INV:\n",
            "Thellll d arull th, hetaigoo d ierin.\n",
            "RD thof asthen or s.\n",
            "T \n",
            "\n",
            "[3m 46s (4100 20%) 2.4538]\n",
            "Wheme whatw I wess Hof ETh adorouicrer thenger te SThe br hare nds couberothil he t,\n",
            "\n",
            "IS:\n",
            "TING mimindr \n",
            "\n",
            "[3m 51s (4200 21%) 2.4668]\n",
            "Wh t, d thans, ys y s we f edus gounou thext my a ar tina y teat ke nd wad he whe wall the sod I a nth \n",
            "\n",
            "[3m 57s (4300 21%) 2.4811]\n",
            "Whthere I w qus nd wir the V:\n",
            "\n",
            "\n",
            "THI nd d\n",
            "RDo ncuise aisert m t ns oulop cere t.\n",
            "\n",
            "O, meeas o s llto ath \n",
            "\n",
            "[4m 2s (4400 22%) 2.4826]\n",
            "Whir hest sthe d ads thareshoushie hethinelinongodof sth hindses fo wimes g\n",
            "S:\n",
            "A etord, mouee f f d bi \n",
            "\n",
            "[4m 6s (4500 22%) 2.4640]\n",
            "Whel be ayend, p buthe t onth counghe yowe w hangs?\n",
            "\n",
            "\n",
            "NGULUCI y fe be, ilur anche s-\n",
            "Yerous s; t.\n",
            "NINR \n",
            "\n",
            "[4m 12s (4600 23%) 2.4604]\n",
            "Whell t y, t blllll he wrcate opteno han ngomier drs ato blyour o be Wwus\n",
            "Frd at thiveast my lexttof t \n",
            "\n",
            "[4m 17s (4700 23%) 2.4528]\n",
            "Whanthestinen ing hio t ghinthues a thotho buth ag wee thainothin ag gans t we saved h as BEORI tole,  \n",
            "\n",
            "[4m 22s (4800 24%) 2.4716]\n",
            "Whord ser\n",
            "Thead iss thel finowathowas we hathoure out brs.\n",
            "\n",
            "\n",
            "As CHENGord toure t beld ad t shof t the  \n",
            "\n",
            "[4m 29s (4900 24%) 2.5030]\n",
            "Wharrm d hend athe Ronourey Genghyonoughathen oncalf t m toler.\n",
            "\n",
            "Thie in me whe athingathonenthade aco \n",
            "\n",
            "[4m 37s (5000 25%) 2.4728]\n",
            "Wh hen ant, thisgan atue\n",
            "BONor ETense'd ondelounouy I rked theand hat! tidoun hy co tondil be, inesire \n",
            "\n",
            "[4m 42s (5100 25%) 2.4364]\n",
            "Whe ber me t\n",
            "ARDUSo s ofe ares be s toourerfe l my wen I ht his.\n",
            "An imerd; m dine me ns butr t; oup mm \n",
            "\n",
            "[4m 47s (5200 26%) 2.5442]\n",
            "Whexchat boreordumoristhertherent tonthe covean, th wo ngry ave by h arethe, ghe.\n",
            "Ancuk fng benthankn\n",
            " \n",
            "\n",
            "[4m 52s (5300 26%) 2.4944]\n",
            "Wh the-f mpt's s athis bl y he aneaverurt ch hed, y, ademaing mes han peshimo t VI:\n",
            "\n",
            "G s as ouat iour  \n",
            "\n",
            "[4m 57s (5400 27%) 2.4272]\n",
            "Whare ghr by aveat at o aririner theserar pare che a;\n",
            "Th thad lo pat d ooulllarteay br RIAnothan thele \n",
            "\n",
            "[5m 3s (5500 27%) 2.4769]\n",
            "Wh ast s ayofrace bere s th ber wol nthashad f ly chy ame co s, y anen my tone.\n",
            "ARD sur heiscore ous n \n",
            "\n",
            "[5m 7s (5600 28%) 2.4309]\n",
            "When?\n",
            "A:\n",
            "\n",
            "OETESiloulind, us, ad thithackendissmy as nstteth hen hyongh'd be su w whayoomiou.\n",
            "LENAndit\n",
            " \n",
            "\n",
            "[5m 13s (5700 28%) 2.4522]\n",
            "Whindyest wer t y my ow mbleou,\n",
            "\n",
            "\n",
            "An l aishapth ble fr de s bis ts IComy o ad bangeameen.\n",
            "\n",
            "\n",
            "Tithesth W \n",
            "\n",
            "[5m 18s (5800 28%) 2.4240]\n",
            "Whe d sed lirk, t s to'mpe ING myoththy therpat y s hy r m ayorimy my angar wine ntharee weas o ar med \n",
            "\n",
            "[5m 22s (5900 29%) 2.5019]\n",
            "Whe tou s t sppres theres my wit an:\n",
            "\n",
            "ARISevenin het n s the he llell; larillo be t owinolllarit ks so \n",
            "\n",
            "[5m 28s (6000 30%) 2.4145]\n",
            "Whe\n",
            "D:\n",
            "\n",
            "The, otr'd athit me, S:\n",
            "\n",
            "\n",
            "STre tothoutis be oued d s, w ls tha chethen, pre co iser Kedaloo, m \n",
            "\n",
            "[5m 33s (6100 30%) 2.4945]\n",
            "Whatr:\n",
            "\n",
            "An the o bu ach inouthe thed th whe prdeit g, wee, s I abe higon whe hare s,\n",
            "ANRO:\n",
            "\n",
            "\n",
            "\n",
            "Ifire bs \n",
            "\n",
            "[5m 40s (6200 31%) 2.4800]\n",
            "Whe we otwelesainearethee hak ce w prore pe t:\n",
            "\n",
            "Ford my, s ano lord tithimy hyo wo iste s l g tr, Ce r \n",
            "\n",
            "[5m 45s (6300 31%) 2.5314]\n",
            "Whhe awin f bether, bl f\n",
            "ARI t ir hot berlengr wald thy m be t hieille t'd fe cray be me t fe cengee o \n",
            "\n",
            "[5m 50s (6400 32%) 2.4795]\n",
            "Whin:\n",
            "\n",
            "ABu ghe be and Lathage adendend durthe andere tourd, omomoungornd hy 's\n",
            "Thind ithious ol at cac \n",
            "\n",
            "[5m 55s (6500 32%) 2.5074]\n",
            "Whis,\n",
            "\n",
            "Gethe, toure f and, to are frithand seranr thethen, f tenthas sowe wono er cell m wnoupou he me \n",
            "\n",
            "[6m 0s (6600 33%) 2.4178]\n",
            "Whereryores be thayss by t tr seathathay ndour, the l, mus t Finostis pomo here wie's;\n",
            "\n",
            "\n",
            "\n",
            "SSThit anome \n",
            "\n",
            "[6m 6s (6700 33%) 2.5056]\n",
            "Wh o; an sir le by towipofou he rtotoo nd m tofar ng t is't aincor y w inoo belardou cocersee\n",
            "ICo d de \n",
            "\n",
            "[6m 10s (6800 34%) 2.4245]\n",
            "Whalingne;\n",
            "\n",
            "YOLUSipifr ms s the inuc thoror ty,\n",
            "\n",
            "Whed t frd, the st pe averin mer had wenovedoreayo ar \n",
            "\n",
            "[6m 16s (6900 34%) 2.4852]\n",
            "Wht he this, withagutitherichede s,\n",
            "\n",
            "Hat ore:\n",
            "Loulons s me ithe bouchere.\n",
            "THe the w alalortereld beman \n",
            "\n",
            "[6m 21s (7000 35%) 2.5235]\n",
            "Whesif fo tis ghin s torouroo be mou pee s mbe I talougs wal ho my,\n",
            "AR:\n",
            "wike, thescithin s amas as nth \n",
            "\n",
            "[6m 25s (7100 35%) 2.5658]\n",
            "Wheare we\n",
            "Ho nthilomens? h t wh LUTHewig n; kepl trs thee s wile s, CHe t shout, t od inatit hit lllis \n",
            "\n",
            "[6m 31s (7200 36%) 2.4792]\n",
            "Wha is.\n",
            "Cie; wheprinern ator\n",
            "\n",
            "BENINGioseree, hakir iser ayst n the I burs gr y mincllde avirs, ngus, I \n",
            "\n",
            "[6m 36s (7300 36%) 2.4436]\n",
            "Wheef t thife w outhe winoulit be theanof fouses In I sor d white\n",
            "I by d thethes ge h bus th megr teas \n",
            "\n",
            "[6m 41s (7400 37%) 2.5012]\n",
            "Whyors;\n",
            "Thereathe: be we lse yolavefoursou mait:\n",
            "ARUSors o me ls be the, cowere ang ssusit Shy wid, to \n",
            "\n",
            "[6m 46s (7500 37%) 2.4355]\n",
            "Whe th suth reato w ngher;\n",
            "O:\n",
            "I INThis be shovimast bo be hee ases sthiounay pu?\n",
            "R: t.\n",
            "Th thelelathe k \n",
            "\n",
            "[6m 51s (7600 38%) 2.4786]\n",
            "Why al beatello nd lspou d:\n",
            "O:\n",
            "MENAn owave at ltharrorsthe thath alll eth s w t ares ndouthikete,\n",
            "S:\n",
            "H \n",
            "\n",
            "[6m 57s (7700 38%) 2.4700]\n",
            "Whe than mer, he e haca teredener orere wins o y ou an thatis the thterre t hont omumyos thean he pak  \n",
            "\n",
            "[7m 1s (7800 39%) 2.5176]\n",
            "Whe s win t hataswansthitis oman ayous,\n",
            "Y:\n",
            "Cougher hasuthit h on that y therolourorors mule thes sltt  \n",
            "\n",
            "[7m 8s (7900 39%) 2.5225]\n",
            "Whoworeporuncakie blld fthe thashe blounoneshe d t my, his; y hereindere alondor is ssotofourakorerech \n",
            "\n",
            "[7m 13s (8000 40%) 2.5245]\n",
            "Whe yo ad fincol wo stitanor aly it in oolous n, k t co wing mappu pap n war se th ad sthe onond to bl \n",
            "\n",
            "[7m 18s (8100 40%) 2.4726]\n",
            "Why t l by?\n",
            "\n",
            "\n",
            "I thyo ad, s t th pe, re e, ourin h, me tisout singu merin e wecer yothit se tthebu tere \n",
            "\n",
            "[7m 23s (8200 41%) 2.4575]\n",
            "Whe\n",
            "Fillfours athewes tharichomang merisofin t, ot imothadir than gh weas, ind w be, my tele n-th cond \n",
            "\n",
            "[7m 28s (8300 41%) 2.4826]\n",
            "Whe ves y hed g ailiree sof y mpaiarniech my ou prs t the st noure dange p atrf isowisthe me ba ind t  \n",
            "\n",
            "[7m 34s (8400 42%) 2.5121]\n",
            "Wh s st d, iufam, fothans bleal't,\n",
            "Th manole bul ss wit histhe on s therd blld welissichif d sptld sth \n",
            "\n",
            "[7m 39s (8500 42%) 2.4936]\n",
            "Whearsese thernoreathovirth de ase ind he s, ne woure as m tidithet teout swappe lll, il y ceaven:\n",
            "ANR \n",
            "\n",
            "[7m 44s (8600 43%) 2.4474]\n",
            "Whe hind s,\n",
            "Ty heanor in angheve y ureit; d cr, he y toumiver than s po are lled thiof athereiks ishee \n",
            "\n",
            "[7m 49s (8700 43%) 2.4607]\n",
            "Wheland\n",
            "\n",
            "\n",
            "\n",
            "I:\n",
            "F no mys qu bys!\n",
            "Slouthad s thoout scownd pare men of tand fe t y gr mincor d ne d he ts \n",
            "\n",
            "[7m 54s (8800 44%) 2.4521]\n",
            "Where chaku whes ithakesouthie min foamin of houcour s frr, wean ts angron d me h re:\n",
            "\n",
            "\n",
            "\n",
            "Whopecun then \n",
            "\n",
            "[8m 0s (8900 44%) 2.4336]\n",
            "Whanave d INELO: IOUSINRofar inorrd suthit ignt touletere:\n",
            "\n",
            "Buts stheathind g mpl I'sth m min g emocay \n",
            "\n",
            "[8m 4s (9000 45%) 2.4741]\n",
            "Where dinowaid thy uirathald n Whicth br o irourooren winy beazeorthal t fo re becound oomar,\n",
            "Wieneeri \n",
            "\n",
            "[8m 9s (9100 45%) 2.4882]\n",
            "Wh be dime t t tave he th lan sthifayon:\n",
            "AR:\n",
            "Wh faru by ha beaninathano tend\n",
            "\n",
            "INo\n",
            "Cou thard wer;\n",
            "\n",
            "\n",
            "Wha \n",
            "\n",
            "[8m 15s (9200 46%) 2.4408]\n",
            "Wh ar nench lay, m wearoull f, wow.\n",
            "\n",
            "Lld alich, oren a of he ne thas, tho or my\n",
            "ASThe, fila blathiler; \n",
            "\n",
            "[8m 20s (9300 46%) 2.4625]\n",
            "Whe I'sinnct on he bepo stin pe tosth atr Du we esier cee saprithead go toongoun borspr hour iiplay ss \n",
            "\n",
            "[8m 26s (9400 47%) 2.4715]\n",
            "Whidshtthin wers ond aneene lacath.\n",
            "ANod t as t but s as ithisethone cathacand thea t s ss ineald, t t \n",
            "\n",
            "[8m 31s (9500 47%) 2.4969]\n",
            "Whe me Shiuroul hin thenge r t wa leg mes\n",
            "Lomelethoust.\n",
            "\n",
            "Thianout ous g heeanghemeth nth sst arer beat \n",
            "\n",
            "[8m 37s (9600 48%) 2.4755]\n",
            "Whe,\n",
            "Sho vengurthellldimy y y k wim, he? s\n",
            "'s blof I g,\n",
            "\n",
            "YOLAs s the qurul s s l t ces the thy g t het \n",
            "\n",
            "[8m 43s (9700 48%) 2.4733]\n",
            "Whothovexulindd tif d w was touthens, Y:\n",
            "\n",
            "ARONTAsthe mandghaman, y me.\n",
            "LOLee c:\n",
            "Man l you s matnd,\n",
            "NET \n",
            "\n",
            "[8m 48s (9800 49%) 2.4892]\n",
            "Whieroamyofr ter cunt theest toucane by s d be hou omy the!\n",
            "Thes archone\n",
            "'stham 'd d me singr toup t s \n",
            "\n",
            "[8m 54s (9900 49%) 2.4598]\n",
            "Whes ouithatothavenckensouthel.\n",
            "Thyormy tovean an n culard ad wor oo hr me ste ENTI w e y bere an ceve \n",
            "\n",
            "[8m 58s (10000 50%) 2.4376]\n",
            "Wharsasoucer be, w nds la paichake dild m tod t, M:\n",
            "T:\n",
            "\n",
            "JUSocefrind,\n",
            "Notho than t,\n",
            "Nompout w l:\n",
            "Terthe \n",
            "\n",
            "[9m 4s (10100 50%) 2.5205]\n",
            "Whe?\n",
            "Thun ound lis wnd a oucere winde supeldr I m inowinous ade s,\n",
            "Whispilin tind:\n",
            "\n",
            "CII'de wisar busav \n",
            "\n",
            "[9m 9s (10200 51%) 2.5409]\n",
            "Whed ce pomy INENGLe t tlaralllala anorer s y e h warsed marilo trentr amougat noraig;\n",
            "Q be fande ind  \n",
            "\n",
            "[9m 14s (10300 51%) 2.4666]\n",
            "Whiliotorsth ge wo lo, crt ond\n",
            "Whe the bethen blat sthope'tyean:\n",
            "\n",
            "\n",
            "I masthe pp;\n",
            "MANouelfaldure s he.\n",
            "T \n",
            "\n",
            "[9m 19s (10400 52%) 2.4524]\n",
            "Whit puthen,\n",
            "A pev'swis d het wise l! f t s his, t hfor l s, thour lellisth at t th co waveet bernd t  \n",
            "\n",
            "[9m 24s (10500 52%) 2.4749]\n",
            "Whetore t car, mpapounen is we ar d cur' haro-t there co ye ndengis my. bowe f orithyour bas bond thet \n",
            "\n",
            "[9m 30s (10600 53%) 2.5276]\n",
            "Whiseakst, t, him Moukould yowhe aifat t ngofithaspalise s anethe sind, f, BENofe rdg g ind ily wangit \n",
            "\n",
            "[9m 35s (10700 53%) 2.4618]\n",
            "Whe, s het withalingheain\n",
            "S:\n",
            "NGLLAMyon med f s y thy phachanes.\n",
            "Yen ssens ye ithere w hit:\n",
            "Forishy:\n",
            "Ta \n",
            "\n",
            "[9m 40s (10800 54%) 2.5032]\n",
            "Wht her gess,\n",
            "A kngheshichor n ioulald DWher's u IUEOfo, ge d.\n",
            "Kpon, g owee he thall thout irdy re cof \n",
            "\n",
            "[9m 45s (10900 54%) 2.4853]\n",
            "Whene lo aprer y tho k cone the meitowhander ha myon m st ine winchee d wid o mf be t t\n",
            "MEfo at mend t \n",
            "\n",
            "[9m 50s (11000 55%) 2.4025]\n",
            "Whe nd ce fang nded yof br sed s y bat tin bete I's, ory winelour h the theththang ind, il hone th f a \n",
            "\n",
            "[9m 56s (11100 55%) 2.4208]\n",
            "Who tgu me KUS:\n",
            "TUCit tave icororowimayof t my nd yor s, ne witr mirours thoullayoure therundsest, STi \n",
            "\n",
            "[10m 0s (11200 56%) 2.4486]\n",
            "Whopes your ou toveru denchonde.\n",
            "RI' ge therithe hed.\n",
            "\n",
            "Plander d f ffouritomathe s myon\n",
            "\n",
            "OROLIO:\n",
            "HAnd  \n",
            "\n",
            "[10m 6s (11300 56%) 2.4992]\n",
            "Whelico iverendiathear t it d d hay he chasth nd t byoverit hand at ucail ngeathateest rs yon tou ino  \n",
            "\n",
            "[10m 11s (11400 56%) 2.4934]\n",
            "Whatn,\n",
            "\n",
            "AROfrur,-yor d orilderen he hath thinoff be sothing co thompler swhave hordsthe sth hy ablithe \n",
            "\n",
            "[10m 15s (11500 57%) 2.4226]\n",
            "Wher gous twed\n",
            "FUCEShaly hisher t ys, ou ll se, pave ig te hut t,\n",
            "Fre hess theshie tho me.\n",
            "And beay av \n",
            "\n",
            "[10m 21s (11600 57%) 2.4995]\n",
            "Whir, INE st by ouswig t lat-s poushackicend ICowhey we, y geat darot te potheie hy wan:\n",
            "Itheakesees r \n",
            "\n",
            "[10m 26s (11700 58%) 2.4991]\n",
            "Whorenkishimeallthe pheadimy ind thad is ms ithen nd athinds myouiss h IO:\n",
            "Anthy tonithire out he p an \n",
            "\n",
            "[10m 31s (11800 59%) 2.4986]\n",
            "Wheat d an,\n",
            "\n",
            "\n",
            "Prerasick wilore nmand t t ama o be wtalyo owhesay gelacanowato tshe chlonorrer ters ffe \n",
            "\n",
            "[10m 36s (11900 59%) 2.4635]\n",
            "Whertherehe thichees wind tr CORo inomesthieer we tharen he r s f dse, hat nom ncofave Che durthemond  \n",
            "\n",
            "[10m 41s (12000 60%) 2.5026]\n",
            "Wherer my there.\n",
            "\n",
            "I novere fonger ivend fad t hert icalonghe betheirothe mes d hikt oure\n",
            "BINETe y me b \n",
            "\n",
            "[10m 47s (12100 60%) 2.4300]\n",
            "Whelie o, der he hathemal an han n, helu Bomyownd ndin g thenogorsou r s d sse ONCKENTHEOF ang, aveno  \n",
            "\n",
            "[10m 51s (12200 61%) 2.4909]\n",
            "Whand ch, qu fesian, t thatinthe thin thereais urechimot\n",
            "CE:\n",
            "An, thine Bindr, t hy tersthe, ithe tongl \n",
            "\n",
            "[10m 57s (12300 61%) 2.4738]\n",
            "Wher ly, man bere t the ss wour fa awougithid our sithowe Me f bullo are?\n",
            "ANouther ble te lle shendint \n",
            "\n",
            "[11m 2s (12400 62%) 2.4269]\n",
            "Whelll tea nd dvethyonour\n",
            "Anon s bed am tame, f s Her thentrd th g,\n",
            "RIOLI:\n",
            "Thu whe bl w nd whayove pl\n",
            " \n",
            "\n",
            "[11m 7s (12500 62%) 2.3507]\n",
            "Whe'd lll lore wive nealoull berethethen hen halef nd s wicuthit h bevif t; fre?\n",
            "LYo is, d s, odordoum \n",
            "\n",
            "[11m 13s (12600 63%) 2.4961]\n",
            "Whomeye ur al twhe shomy ho dy s m thouss chit thien harthitoundeingranghere m m\n",
            "Berug,\n",
            "Hrg athy nd an \n",
            "\n",
            "[11m 17s (12700 63%) 2.4504]\n",
            "Wheca aldingr t m sit thowalys I ndort n d, t ato y m ETo Rofowoth shainy w nd, tovend ts fore weliss' \n",
            "\n",
            "[11m 23s (12800 64%) 2.4836]\n",
            "Whe,\n",
            "\n",
            "Hyot anges maretr t IIOLA herighat morext ssde meichent y d,\n",
            "S:\n",
            "I h athimutee hioous\n",
            "\n",
            "S:\n",
            "Whes us \n",
            "\n",
            "[11m 28s (12900 64%) 2.4636]\n",
            "Wher t winthe st tharsthes! hig PLETIsero, the the hee k henor ll s oret,\n",
            "Thit theshad wntind, he the  \n",
            "\n",
            "[11m 32s (13000 65%) 2.4355]\n",
            "Wh at IUCOullle y you thatervelencat as, at bot wir\n",
            "THay wasothes arourea d heroy anthet coflous wiuou \n",
            "\n",
            "[11m 38s (13100 65%) 2.4737]\n",
            "Wh s all hieetomid IO:\n",
            "\n",
            "A:\n",
            "As:\n",
            "wiavio ching thillio asod,\n",
            "\n",
            "PHPunod he d athe IVad.\n",
            "\n",
            "MEG bur Ind w,\n",
            "\n",
            "O: \n",
            "\n",
            "[11m 43s (13200 66%) 2.4278]\n",
            "Wh thel slinge meais thmur chapes ct A:\n",
            "Ange my\n",
            "Therindr hur,\n",
            "Wise y f th: h'stheasit w h man heceald  \n",
            "\n",
            "[11m 49s (13300 66%) 2.4823]\n",
            "Whest the t yod wounomoo, t onkecithan f at, tepispr hes me t howimyothe ar, avend'd fo helllevaverato \n",
            "\n",
            "[11m 53s (13400 67%) 2.5453]\n",
            "Whtos d t g,\n",
            "ANI to cetl he fre thatth w, p an s fen lithe w s wourerre:\n",
            "KI stis,\n",
            "Whit f t\n",
            "\n",
            "T:\n",
            "Therth  \n",
            "\n",
            "[11m 58s (13500 67%) 2.4721]\n",
            "Whe mur sesst lloithintantheactron w re begllllt whirt CEN thefangancor arine slfere!\n",
            "And, e peve th k \n",
            "\n",
            "[12m 4s (13600 68%) 2.5178]\n",
            "Whenof y ith helpaleseng woule f nthe that sseenongllld\n",
            "An ind cespouckeatoomy t mblinthe an y,\n",
            "\n",
            "MERD: \n",
            "\n",
            "[12m 9s (13700 68%) 2.5067]\n",
            "Whers the ces st:\n",
            "\n",
            "A ir pere t keas incownde thatomep?\n",
            "\n",
            "Meng s.\n",
            "Ho n athesee atol a S:\n",
            "Wht there bon?\n",
            " \n",
            "\n",
            "[12m 14s (13800 69%) 2.5232]\n",
            "Wh therestobry ther's acor tr t l mend n sthisead kinckeay se below im,\n",
            "Whe d todo ilisalour, k, m fer \n",
            "\n",
            "[12m 19s (13900 69%) 2.5784]\n",
            "Whak hathengus thoftheave f minor som pr'dins thee'\n",
            "KI ale mponote as y y oun athint nd my p honsovera \n",
            "\n",
            "[12m 24s (14000 70%) 2.4795]\n",
            "Whrer y, thore cout bat bas, goor imur t the the meven bas I'\n",
            "Whougethy tha t t ghe wiry th an we y, o \n",
            "\n",
            "[12m 29s (14100 70%) 2.5614]\n",
            "Whe ngonou Thare f ngher belis, isu'lor y\n",
            "AUCalo t, she pe, me, the be,\n",
            "\n",
            "Youel der:\n",
            "Core.\n",
            "Fr hivowofri \n",
            "\n",
            "[12m 34s (14200 71%) 2.5332]\n",
            "Whof haceroy malll ishiot 'd, o butor dilan,\n",
            "\n",
            "Nore?\n",
            "Thacont ll l wissist htl our wengh enlleard tocher \n",
            "\n",
            "[12m 40s (14300 71%) 2.5545]\n",
            "Whe hat mearury faimars--delowiert he erd, cerm he acear, d.\n",
            "TIO:\n",
            "DIZO nd, n, he as g mif, thangs t ma \n",
            "\n",
            "[12m 45s (14400 72%) 2.4472]\n",
            "Whenthe why In st mithe t, mowise su wh sthy tilere ardereseat as leve 'my iled INore we alang ate aig \n",
            "\n",
            "[12m 49s (14500 72%) 2.4508]\n",
            "Whicy owin adend, sedamaser dird thirtwher catourk erayo wasove sthrilou ce min me t Coo he.\n",
            "\n",
            "\n",
            "This,\n",
            "I \n",
            "\n",
            "[12m 55s (14600 73%) 2.4367]\n",
            "Wharthe;\n",
            "Ge thurt fesprme, f f t ou lome the ang.\n",
            "KI bar nd wou f'swouthofou s berot be, butar this l  \n",
            "\n",
            "[13m 0s (14700 73%) 2.4921]\n",
            "Wh aray thiman shanthatout ticire thad wios ave s ford mee anghe r abe y teyounth'sot thour tothoucall \n",
            "\n",
            "[13m 6s (14800 74%) 2.5598]\n",
            "Wheaveabe f wofou Mough the tond t mith dourind hordrourod t as waldound th andeat athangis ongre win  \n",
            "\n",
            "[13m 10s (14900 74%) 2.4862]\n",
            "Whafo t wthee thise o m k d bernd pathanf t.\n",
            "CUCABe bl t telyotouthy this y tove fo s wagoormy f ar ta \n",
            "\n",
            "[13m 15s (15000 75%) 2.5234]\n",
            "Whels a hansut angis meshind o y fullas,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "D:\n",
            "Anof acoue: se isuse me tat g n t wea th:\n",
            "IARUS:\n",
            "KI bo \n",
            "\n",
            "[13m 21s (15100 75%) 2.5038]\n",
            "Whouthe ne he lucourerieshor nte thurondesherel E:\n",
            "Thourad n y s bud, y ant harte ser ashard yothoncla \n",
            "\n",
            "[13m 25s (15200 76%) 2.4431]\n",
            "Whie s nd thr n y sticeave.\n",
            "I\n",
            "Bur l an an,\n",
            "An bl whar msur thend rd ices ars Besesowiveaume swhances t \n",
            "\n",
            "[13m 31s (15300 76%) 2.4349]\n",
            "Wheepery o torellld lothecall ond nir.\n",
            "\n",
            "\n",
            "GEE ll the tind thand h,\n",
            "\n",
            "The llithat bot tho t meres ato 's  \n",
            "\n",
            "[13m 36s (15400 77%) 2.4952]\n",
            "Whe athenthforsho t sethoull m meitnsthifar you htelothilind llas, owomerisay whal' t ce mstuthavis to \n",
            "\n",
            "[13m 41s (15500 77%) 2.4874]\n",
            "Whowowathiter my wir igharedome shadinentodereis.\n",
            "Buthethaind ait and hy INowedanyorar,\n",
            "\n",
            "\n",
            "\n",
            "TRK:\n",
            "CUThe  \n",
            "\n",
            "[13m 46s (15600 78%) 2.4902]\n",
            "Whe faieret ththere brustanine y, by berelys:\n",
            "\n",
            "Theshe f bethow BY:\n",
            "I l t thes turd fure\n",
            "Foang imewhe r \n",
            "\n",
            "[13m 51s (15700 78%) 2.4328]\n",
            "Whingn, ar:\n",
            "BO ioupuror har hans tht at t t mef--\n",
            "Mo s st.\n",
            "S:\n",
            "\n",
            "T:\n",
            "\n",
            "OMO:\n",
            "May mawheave.\n",
            "sos int, m paie: \n",
            "\n",
            "[13m 57s (15800 79%) 2.4573]\n",
            "Whord an those youree my me whinond ime he m a thivee k wiemo he cche o tr nthed she lay hiveno alerol \n",
            "\n",
            "[14m 1s (15900 79%) 2.4997]\n",
            "Whead pokesheverot hore\n",
            "Anone cou n\n",
            "GO, uros; de ces ng ret the illld athe thangre theout heme br then \n",
            "\n",
            "[14m 7s (16000 80%) 2.4238]\n",
            "Whealathe obes I s anthe t thand h our y t sere whand cy wilesour dstheay t:\n",
            "\n",
            "O: he norer mom ousupick \n",
            "\n",
            "[14m 12s (16100 80%) 2.5454]\n",
            "Whearernt tlth br ise yonot me\n",
            "Butist sthitithatanghass chichee s hidere orar tharo by the t, ho ithin \n",
            "\n",
            "[14m 17s (16200 81%) 2.4645]\n",
            "Wheds thes INI ougong'thanoofomo mesth be le kin\n",
            "t\n",
            "PRI s'd t me bes itise io und e anges s ke S:\n",
            "\n",
            "Y:\n",
            "G \n",
            "\n",
            "[14m 22s (16300 81%) 2.4500]\n",
            "Whe k f amo ithipesseren:\n",
            "PE itou ss stha hecoupthee, pomearad s, thelofof horsoud the ans.\n",
            "BRENThotea \n",
            "\n",
            "[14m 27s (16400 82%) 2.4624]\n",
            "Whe\n",
            "\n",
            "ARESherrerir, s bueat ss h y oushe, tono t rthade w ginow satheamatl her d t y gedinenge me\n",
            "Her i \n",
            "\n",
            "[14m 32s (16500 82%) 2.4334]\n",
            "Why ke y IUENThorund e bun an are burearas res, ourinthar, st S:\n",
            "S:\n",
            "I ay me d trourofaugemer hit ithou \n",
            "\n",
            "[14m 37s (16600 83%) 2.4419]\n",
            "Whintidinllor cans n while ld te arthy me, t t testham tousp wine that wik thathy f windise schiber, i \n",
            "\n",
            "[14m 42s (16700 83%) 2.5144]\n",
            "Whand le asistis r se tlare hot, pome be the y catat h ang bur iens t has ithirid d y?\n",
            "LELERorat tiou. \n",
            "\n",
            "[14m 48s (16800 84%) 2.4823]\n",
            "Whevef be avo whe ck'llicelle taistht y me wat wineng ar RERDIINCLes s are bus wok'dus t s bl sonot il \n",
            "\n",
            "[14m 52s (16900 84%) 2.4844]\n",
            "Whah ndeate st wobrsefathe, wn f ime w the d.\n",
            "\n",
            "Hulesthed plick oono heremerar bleseaves ll allthin,\n",
            "BT \n",
            "\n",
            "[14m 58s (17000 85%) 2.5098]\n",
            "Whe f y g s whies wove l hero wh whood othe stle Petonomeangourf we IOR:\n",
            "Thanonourthy m sesto maces la \n",
            "\n",
            "[15m 3s (17100 85%) 2.5164]\n",
            "Whild eng then cere s, we id thororyomy n,\n",
            "Ast she qull t wos, g berathau prn d h iorat y wor iste wis \n",
            "\n",
            "[15m 8s (17200 86%) 2.5265]\n",
            "Wh hed.\n",
            "Fo nthis oully,\n",
            "\n",
            "Mrdot tht stren d\n",
            "\n",
            "Thalit lat ancoor barst:\n",
            "The iveserd d\n",
            "'s m andourken buby \n",
            "\n",
            "[15m 13s (17300 86%) 2.4408]\n",
            "Whe at w ou s, w ll bury, w, bofithe s tincthont f sto tramoot to t d malll soter fo pareerthol h I w  \n",
            "\n",
            "[15m 18s (17400 87%) 2.4964]\n",
            "Whinountho tow hen den my n clonghe wharther wamewourier wesorodint! t nthe whe Benoutoneid ounershe m \n",
            "\n",
            "[15m 23s (17500 87%) 2.4672]\n",
            "Whelevend han; t tho y t bulloserin t heshe meatout u isou withave!\n",
            "ANINBUThyofou in RTI st yo ound te \n",
            "\n",
            "[15m 28s (17600 88%) 2.4763]\n",
            "Who; mst t, y aforeratherinee el the.\n",
            "Tout, be, ald t our,\n",
            "Louthathares he the than ceatote we tre s,  \n",
            "\n",
            "[15m 33s (17700 88%) 2.4932]\n",
            "Whe\n",
            "Thifo t oichowercton hean\n",
            "BEYCHou s stheryouly ceat sprd f hese toucout ps w ithe owild s t he Rid \n",
            "\n",
            "[15m 39s (17800 89%) 2.4508]\n",
            "Whino, t t stonthat'd son s hea te ond wonowhendess'dereate mer, thed itsonerenad whire bl I or on ith \n",
            "\n",
            "[15m 44s (17900 89%) 2.4440]\n",
            "Whe cenond he bes t 'deowe ureall an hentheind thol s t avathathe wom.\n",
            "\n",
            "I IO:\n",
            "No gher aneander ht n TH \n",
            "\n",
            "[15m 49s (18000 90%) 2.4915]\n",
            "Whoun\n",
            "OLI waverel, pr kelllly st l t the isthomewave tonghir,\n",
            "Thintis.\n",
            "HI tour whith corolieane, IZan  \n",
            "\n",
            "[15m 54s (18100 90%) 2.4547]\n",
            "Whe s t gr of mor shenoreng, of atongurdu the s ato tit s wine tha tof f akit ue artlint t I f make h  \n",
            "\n",
            "[15m 59s (18200 91%) 2.5153]\n",
            "Wh wind u thir tosuis t in s n tughif thetar ht ise our olilll bll uchif s bre l limirenom h,\n",
            "Andoulll \n",
            "\n",
            "[16m 4s (18300 91%) 2.4855]\n",
            "Whed t his\n",
            "Thendoldy t whe, le we thit toffonemesoungean aw mo I he heeed h:\n",
            "Thar sessom woukendd ghe  \n",
            "\n",
            "[16m 9s (18400 92%) 2.4507]\n",
            "Whad mere t ouerou rnor t--\n",
            "VIO! s by s bers d swighivir nt lived.\n",
            "TOvetwint oknteay inifarer wore fou \n",
            "\n",
            "[16m 14s (18500 92%) 2.4584]\n",
            "Who arere aver bl me tillomal gomy that theole ano to se irck,\n",
            "I s s buren ldeicong mowe we mesishe to \n",
            "\n",
            "[16m 20s (18600 93%) 2.4607]\n",
            "Whilakst\n",
            "Fe bucrovithes an gell mend mathay g helles, LUCHE:\n",
            "Ofourr:\n",
            "RENGI med bend dernd g thend cat, \n",
            "\n",
            "[16m 24s (18700 93%) 2.3983]\n",
            "Whis thelearbes thanceanchisho loflis, athastht w t fie'scous y-\n",
            "COr mea t tat dsthes th path g ands m \n",
            "\n",
            "[16m 30s (18800 94%) 2.5489]\n",
            "Wh sthyowisthan, t pr s, lea bun momald cet anale then yof t ala, tour a heathy ho ange bomy wininond  \n",
            "\n",
            "[16m 35s (18900 94%) 2.4819]\n",
            "Whisd maure f anar he othe e teranthoncandat sus meng d af car s whe leathanound keathe hooneathengmin \n",
            "\n",
            "[16m 40s (19000 95%) 2.4314]\n",
            "Whound br ustheathishoy inthr faith,\n",
            "Yomilearesweay thond, whoof bl ase Fowe, mathio thereras cay fano \n",
            "\n",
            "[16m 45s (19100 95%) 2.5081]\n",
            "Wh'thes s thepld sh jur thend, ed lemyo t wo ost: s t,\n",
            "\n",
            "\n",
            "\n",
            "NGay e mers, ther om, igndouround thant thea \n",
            "\n",
            "[16m 50s (19200 96%) 2.4487]\n",
            "Whar Has hean we l anullow, heallan s meagloour ir: t t m frd the pulfat mef sous,\n",
            "I, ay ano s E:\n",
            "AULA \n",
            "\n",
            "[16m 56s (19300 96%) 2.5069]\n",
            "Wherete p ad l p s ond amirakn lois s\n",
            "Tordy pon, owiceche s\n",
            "\n",
            "\n",
            "Brd\n",
            "Aphe y!\n",
            "LIUCE:\n",
            "PONG t hy myeror wire \n",
            "\n",
            "[17m 0s (19400 97%) 2.4343]\n",
            "Whe you de, ge ST:\n",
            "\n",
            "Tanone h ou nou b t cheico othofo he d f me ch thanyous homyote the omes h I d yo  \n",
            "\n",
            "[17m 6s (19500 97%) 2.4994]\n",
            "Whey t w ur thaver owin mot he EN: t:\n",
            "\n",
            "Wed whed oused hest ey sed I mbe sthe s wou go m furbor thetond \n",
            "\n",
            "[17m 11s (19600 98%) 2.4770]\n",
            "Whererd hat bo bere o wate t t tere thithelid touishamacalle a thyo anir s ms y an onot t be the.\n",
            "ars, \n",
            "\n",
            "[17m 16s (19700 98%) 2.4782]\n",
            "Whengue acll Alongie ithonsthour icovedgouthy ave, ce cowis\n",
            "Ha pl, s lld t heds adee d odimyow'sthashe \n",
            "\n",
            "[17m 22s (19800 99%) 2.4415]\n",
            "Whaget l gh hanethy, hout pe llond t besar hinthy t d gntou he t l t heathe? thyow!\n",
            "TENAThond, ore hon \n",
            "\n",
            "[17m 27s (19900 99%) 2.4578]\n",
            "Whin ndeallonghare mond be cre, d d d theo is geeme t t Covenonor aspe se ser.\n",
            "O:\n",
            "NCKEThe p h ts thend \n",
            "\n",
            "[17m 33s (20000 100%) 2.4605]\n",
            "Wh, arsere thevenge-\n",
            "QUCKes\n",
            "Lhand, thithaveangr, stis whan at ithend wiredis theadwo burthe he and or. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "###Parameters\n",
        "n_epochs = 20000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "hidden_size = 100\n",
        "n_layers = 5\n",
        "lr = 0.005\n",
        "batch_size = 16\n",
        "chunk_len = 80\n",
        "\n",
        "####\n",
        "\n",
        "model = RNN(n_characters, hidden_size, n_characters, n_layers) #create model\n",
        "model_optimizer = torch.optim.Adam(model.parameters(), lr=lr) #create Adam optimizer\n",
        "criterion = nn.CrossEntropyLoss() #chose criterion\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "\n",
        "def train(inp, target):\n",
        "    \"\"\"\n",
        "    Train sequence for one chunk:\n",
        "    \"\"\"\n",
        "    #reset gradients\n",
        "    model_optimizer.zero_grad() \n",
        "    \n",
        "    # predict output\n",
        "    output = model(inp)\n",
        "    \n",
        "    #compute loss\n",
        "    loss =  criterion(output.view(batch_size*chunk_len,-1), target.view(-1)) \n",
        "\n",
        "    #compute gradients and backpropagate\n",
        "    loss.backward() \n",
        "    model_optimizer.step() \n",
        "\n",
        "    return loss.data.item() \n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train(*random_training_set(chunk_len,batch_size))  #train on one chunk \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(generate(model,'Wh', 100), '\\n')\n",
        "       \n",
        "\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        loss_avg = 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "392ec37e",
      "metadata": {
        "id": "392ec37e"
      },
      "source": [
        "## Visualize loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "caf419b5",
      "metadata": {
        "id": "caf419b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8c24863e-cf4c-4633-bec2-cf6814b46ea2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f06712c3e50>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eab32c42",
      "metadata": {
        "id": "eab32c42"
      },
      "source": [
        "## Try different temperatures\n",
        "\n",
        "Changing the distribution sharpness has an impact on character sampling:\n",
        "\n",
        "more or less probable things are sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b2273e75",
      "metadata": {
        "id": "b2273e75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb43251-9446-4637-efe7-e017efd5aa89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thalle hetig alathat woe ncecls akee doranongice thaglt, p whinsoant in l d andot t nd til hittheger\n",
            "Tyondoure CO:\n",
            "CS:\n",
            "S:\n",
            "IO:\n",
            "Seat I'd 'nd.\n",
            "Ousthad:\n",
            "Se t fan. ire ss cit wnd d\n",
            "MELUCot ne te w, ot ha th\n",
            "----\n",
            "Th adrareathoulle min, ato awan, ay; cit th,\n",
            "Y:\n",
            "Whthe br t bustheathe ure thit sw, coul me, t Watoit t Ge hee s acerif de thirineetha ar vere the:\n",
            "\n",
            "LAnd is leg ICI tagseal mourirdon t hir'e ERDI t he ST\n",
            "----\n",
            "Than hape pr the th.\n",
            "TIO:\n",
            "\n",
            "Th the I ine mend the us the t t my, ir st t and ce hanthe this sthareathe the, d this I heard mind banghe the are thithe or the thithe h we heathe le t in ce wingis win I t w\n",
            "----\n",
            "The the I thanghino the the the t the it thathe the t the thange thend the the the athe the s the t s the the ther thind t be the theathe the thind ther t s and thathe thind thind wis the thathe thithe \n",
            "----\n",
            "The the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the th\n"
          ]
        }
      ],
      "source": [
        "print(generate(model,'T', 200, temperature=1))\n",
        "print(\"----\")\n",
        "print(generate(model,'Th', 200, temperature=0.8))\n",
        "print(\"----\")\n",
        "\n",
        "print(generate(model,'Th', 200, temperature=0.5))\n",
        "print(\"----\")\n",
        "\n",
        "print(generate(model,'Th', 200, temperature=0.3))\n",
        "print(\"----\")\n",
        "\n",
        "print(generate(model,'Th', 200, temperature=0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc3dea6",
      "metadata": {
        "id": "9cc3dea6"
      },
      "source": [
        "### Improving this code:\n",
        "\n",
        "(a) Tinker with parameters:\n",
        "\n",
        "- Is it really necessary to have 100 dims character embeddings\n",
        "- Chunk length can be gradually increased\n",
        "- Try changing RNN cell type (GRUs - LSTMs)\n",
        "\n",
        "(b) Add GPU support to go faster\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8b48332e",
      "metadata": {
        "id": "8b48332e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}