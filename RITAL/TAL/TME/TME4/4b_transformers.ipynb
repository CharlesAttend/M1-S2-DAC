{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlesAttend/M1-S2-DAC/blob/main/RITAL/TAL/TME/TME4/4b_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Warning : \n",
        "# Do \"File -> Save a copy in Drive\" before you start modifying the notebook, otherwise your modifications will not be saved."
      ],
      "metadata": {
        "id": "YPB2EK9FEiMp"
      },
      "id": "YPB2EK9FEiMp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT for Sentiment Analysis "
      ],
      "metadata": {
        "id": "_UFwj3KNufA4"
      },
      "id": "_UFwj3KNufA4"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "IlFyycx9qLTP"
      },
      "id": "IlFyycx9qLTP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e14ce48",
      "metadata": {
        "id": "6e14ce48"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading large review movie dataset (50000 reviews in train, 50000 reviews in test)"
      ],
      "metadata": {
        "id": "BtKn-7auvbsh"
      },
      "id": "BtKn-7auvbsh"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://thome.isir.upmc.fr/classes/RITAL/json_pol"
      ],
      "metadata": {
        "id": "a5i1H9--qZsC"
      },
      "id": "a5i1H9--qZsC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c40511e",
      "metadata": {
        "id": "6c40511e"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "# Loading json\n",
        "with open(\"./json_pol\",encoding=\"utf-8\") as f:\n",
        "    data = f.readlines()\n",
        "    json_data = json.loads(data[0])\n",
        "    train = json_data[\"train\"]\n",
        "    test = json_data[\"test\"]\n",
        "    \n",
        "\n",
        "# Quick Check\n",
        "counter_train = Counter((x[1] for x in train))\n",
        "counter_test = Counter((x[1] for x in test))\n",
        "print(\"Number of train reviews : \", len(train))\n",
        "print(\"----> # of positive : \", counter_train[1])\n",
        "print(\"----> # of negative : \", counter_train[0])\n",
        "print(\"\")\n",
        "print(train[0])\n",
        "print(\"\")\n",
        "print(\"Number of test reviews : \",len(test))\n",
        "print(\"----> # of positive : \", counter_test[1])\n",
        "print(\"----> # of negative : \", counter_test[0])\n",
        "\n",
        "print(\"\")\n",
        "print(test[0])\n",
        "print(\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the Tokenizer"
      ],
      "metadata": {
        "id": "0dsRcmntwfOH"
      },
      "id": "0dsRcmntwfOH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4381e234",
      "metadata": {
        "id": "4381e234"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment the Tokenizer on the first train review"
      ],
      "metadata": {
        "id": "GPTSFflDwkoh"
      },
      "id": "GPTSFflDwkoh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc98b0c",
      "metadata": {
        "id": "ddc98b0c"
      },
      "outputs": [],
      "source": [
        "maxL = 512 # Max length of the sequence\n",
        "\n",
        "string_tokenized = tokenizer.encode_plus(train[0][0], return_tensors=\"pt\", \n",
        "                                        add_special_tokens=True,  # add '[CLS]' and '[SEP]'\n",
        "                            max_length=maxL,  # set max length\n",
        "                            truncation=True,  # truncate longer messages\n",
        "                            #pad_to_max_length=True\n",
        "                            padding='max_length',  # add padding\n",
        "                            return_attention_mask=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the tokenizer string_tokenized (class BatchEncoding) returns two elements:\n",
        "\n",
        "\n",
        "*   string_tokenized['input_ids']: the index of each token in the dictionary\n",
        "*   string_tokenized['attention_mask']: a binary mask (0 to ignore the token, 1 to consider it). This is because we need tensor a fixed length and we have reviews with a variable number of words\n",
        "\n"
      ],
      "metadata": {
        "id": "v910nrNVx33z"
      },
      "id": "v910nrNVx33z"
    },
    {
      "cell_type": "code",
      "source": [
        "print(string_tokenized['input_ids'])\n",
        "print(string_tokenized['attention_mask'])"
      ],
      "metadata": {
        "id": "sagULO5nx-3H"
      },
      "id": "sagULO5nx-3H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets download a BERT model for word embedding"
      ],
      "metadata": {
        "id": "TunnUo2p0FT9"
      },
      "id": "TunnUo2p0FT9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fc3269c",
      "metadata": {
        "id": "9fc3269c"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1155599b",
      "metadata": {
        "id": "1155599b"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You can use the BERT model for directly predicting polarity.** Let us apply that on the first review which has been tokenized with string_tokenized."
      ],
      "metadata": {
        "id": "23VAnnrU0QO5"
      },
      "id": "23VAnnrU0QO5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15ab0db",
      "metadata": {
        "id": "a15ab0db"
      },
      "outputs": [],
      "source": [
        "# Some preliminary test\n",
        "import torch\n",
        "import numpy as np\n",
        "b_input_ids = string_tokenized['input_ids']\n",
        "b_input_mask = string_tokenized['attention_mask']\n",
        "\n",
        "model.eval()\n",
        "\n",
        "output = model(input_ids=b_input_ids,attention_mask=b_input_mask, output_hidden_states=True)\n",
        "print(output.logits) # The output of the logit of the two classes (polarity pos/neg)  \n",
        "last_hidden_states = output.hidden_states[-1] # The last layer before the class prediction: tensor of size nBatch (1 here) x MaxL (512) x temb (768)\n",
        "print(last_hidden_states.shape) \n",
        "print(last_hidden_states[0,0,1:10]) # The first 10 value of the first elements (=[CLS] TOKEN)\n",
        "print(f\" norm cls token={np.linalg.norm(last_hidden_states.detach().numpy()[0,0,:])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's tokenize the whole dataset "
      ],
      "metadata": {
        "id": "hdBab99u4HNm"
      },
      "id": "hdBab99u4HNm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40ca05a",
      "metadata": {
        "id": "d40ca05a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "maxL = 512\n",
        "temb = 768\n",
        "\n",
        "\n",
        "inputs_tokens_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "for i in range(len(train)):\n",
        "    if(i%2500==0):\n",
        "        print(i)\n",
        "    string_tokenized = tokenizer.encode_plus(train[i][0], return_tensors=\"pt\", \n",
        "                                        add_special_tokens=True,  # add '[CLS]' and '[SEP]'\n",
        "                            max_length=maxL,  # set max length\n",
        "                            truncation=True,  # truncate longer messages\n",
        "                            #pad_to_max_length=True\n",
        "                            padding='max_length',  # add padding\n",
        "                            return_attention_mask=True)\n",
        "    \n",
        "    # APPEND inputs token and input masks. YOUR CODE HERE\n",
        "    \n",
        "inputs_tokens_test = []\n",
        "attention_masks_test = []\n",
        "\n",
        "for i in range(len(test)):\n",
        "    if(i%2500==0):\n",
        "        print(i)\n",
        "    string_tokenized = tokenizer.encode_plus(test[i][0], return_tensors=\"pt\", \n",
        "                                        add_special_tokens=True,  # add '[CLS]' and '[SEP]'\n",
        "                            max_length=maxL,  # set max length\n",
        "                            truncation=True,  # truncate longer messages\n",
        "                            #pad_to_max_length=True\n",
        "                            padding='max_length',  # add padding\n",
        "                            return_attention_mask=True)\n",
        "    \n",
        "    # APPEND inputs token and input masks. YOUR CODE HERE\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's create a 'TensorDataSet' FOR THE TRAINING SAMPLES where each element is a triplet composed of token word index, token mask, and label"
      ],
      "metadata": {
        "id": "lZrSrBuS-HnW"
      },
      "id": "lZrSrBuS-HnW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93880db1",
      "metadata": {
        "id": "93880db1"
      },
      "outputs": [],
      "source": [
        "# Converting input tokens to torch tensors \n",
        "inputs_tokens_train = torch.cat(inputs_tokens_train, dim=0)\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "\n",
        "\n",
        "# Converting labels to numpy then torch tensor\n",
        "y_train = np.zeros((len(train),))\n",
        "for i in range(len(train)):\n",
        "    y_train[i] = train[i][1]\n",
        "y_train = torch.from_numpy(y_train)\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "train_dataset = TensorDataset(inputs_tokens_train, attention_masks_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's do the same FOR THE TEST SAMPLES "
      ],
      "metadata": {
        "id": "BpuQLQEm_WSC"
      },
      "id": "BpuQLQEm_WSC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88411b6a",
      "metadata": {
        "id": "88411b6a"
      },
      "outputs": [],
      "source": [
        "# Converting input tokens to torch tensors \n",
        "inputs_tokens_test = torch.cat(inputs_tokens_test, dim=0)\n",
        "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
        "  \n",
        "y_test = np.zeros((len(test),))\n",
        "for i in range(len(test)):\n",
        "    y_test[i] = test[i][1]\n",
        "y_test = torch.from_numpy(y_test)\n",
        "\n",
        "test_dataset = TensorDataset(inputs_tokens_test, attention_masks_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you need to clean GPU memory\n",
        "#import gc\n",
        "#gc.collect()\n",
        "#torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "1bX5vtWb_vj8"
      },
      "id": "1bX5vtWb_vj8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Most important STEP: we want to extract the [CLS] representation (1st token of the last layer before logits) for each review, and store it in train and test.  "
      ],
      "metadata": {
        "id": "FoDmvAIO_6l8"
      },
      "id": "FoDmvAIO_6l8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90ee3dc0",
      "metadata": {
        "id": "90ee3dc0"
      },
      "outputs": [],
      "source": [
        "# create DataLoaders with samplers\n",
        "tb = int(100)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=tb,shuffle=False)\n",
        "nbTrain = len(train)\n",
        "f_train = np.zeros((nbTrain, temb))\n",
        "nbtach = int(nbTrain/tb)\n",
        "print(f\"nb batches={nbtach}\")\n",
        "# Comuting CLS features\n",
        "model.cuda()\n",
        "for idx,batch in enumerate(train_dataloader):\n",
        "        # Unpack this training batch from our dataloader:\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        if(idx%10==0):\n",
        "            print(f\"batch {idx} / {nbtach}\")\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_input_mask = batch[1].cuda()\n",
        "        b_labels = batch[2].cuda().long()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            output = model(input_ids=b_input_ids,\n",
        "                                 attention_mask=b_input_mask,\n",
        "                                 #labels=b_labels, \n",
        "                               output_hidden_states=True)\n",
        "            last_hidden_states = output.hidden_states[-1] # WARNING: it is now a batch of size tbatch x nToken x embsize \n",
        "            f_train[idx*tb:idx*tb+tb,:] =  # YOUR CODE HERE. Think in applying .detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract [CLS] token in TEST"
      ],
      "metadata": {
        "id": "srd5tJqyJSRq"
      },
      "id": "srd5tJqyJSRq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aafb30d-357b-46da-a1f8-bfd18832ba24",
      "metadata": {
        "id": "0aafb30d-357b-46da-a1f8-bfd18832ba24"
      },
      "outputs": [],
      "source": [
        "# create DataLoaders with samplers\n",
        "tb = int(100)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=tb,shuffle=False)\n",
        "nbTest = len(test)\n",
        "f_test = np.zeros((nbTest, temb))\n",
        "nbtach = int(nbTest/tb)\n",
        "print(f\"nb batches={nbtach}\")\n",
        "# Comuting CLS features\n",
        "model.cuda()\n",
        "for idx,batch in enumerate(test_dataloader):\n",
        "        # Unpack this training batch from our dataloader:\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        if(idx%10==0):\n",
        "            print(f\"batch {idx} / {nbtach}\")\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_input_mask = batch[1].cuda()\n",
        "        b_labels = batch[2].cuda().long()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # forward propagation (evaluate model on training batch)\n",
        "            output = model(input_ids=b_input_ids,\n",
        "                                 attention_mask=b_input_mask,\n",
        "                                 #labels=b_labels, \n",
        "                               output_hidden_states=True)\n",
        "            last_hidden_states = # YOUR CODE HERE.\n",
        "            #\n",
        "            f_test[idx*tb:idx*tb+tb,:] = # YOUR CODE HERE.\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now save the embedding of each review into disk!"
      ],
      "metadata": {
        "id": "AReISeiZIo9U"
      },
      "id": "AReISeiZIo9U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb81156-d885-4999-a6e7-2d8149173174",
      "metadata": {
        "id": "deb81156-d885-4999-a6e7-2d8149173174"
      },
      "outputs": [],
      "source": [
        "# Saving the features and labels\n",
        "import pickle\n",
        "# Open a file and use dump()\n",
        "with open('train-data.pkl', 'wb') as file:\n",
        "    # A new file will be created\n",
        "    pickle.dump([f_train,y_train], file)\n",
        "\n",
        "with open('test-data.pkl', 'wb') as file:\n",
        "    # A new file will be created\n",
        "    pickle.dump([f_test,y_test], file)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f5f29e",
      "metadata": {
        "id": "67f5f29e"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "  \n",
        "# Open the file in binary mode\n",
        "with open('train-data.pkl', 'rb') as file:    \n",
        "    # Call load method to deserialze\n",
        "    [feature_train, ytrain] = pickle.load(file)\n",
        "\n",
        "# Open the file in binary mode\n",
        "with open('test-data.pkl', 'rb') as file:    \n",
        "    # Call load method to deserialze\n",
        "    [feature_test, ytest] = pickle.load(file)  \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4104eea1",
      "metadata": {
        "id": "4104eea1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "print(feature_train.shape[0])\n",
        "print(feature_test.shape)\n",
        "\n",
        "print(ytrain)\n",
        "print(ytest)\n",
        "print(np.linalg.norm(feature_train[10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finally: train a logistic regression model on top of extracted embeddings. Conclude on the performances of BERT for the sentiment classification task"
      ],
      "metadata": {
        "id": "mx0eec9RIwJr"
      },
      "id": "mx0eec9RIwJr"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}