{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vZzLUr_l_Wfb"
      },
      "source": [
        "# SAM: TP1 Accès aux données avec index \n",
        "\n",
        "Sujet pour étudiants\n",
        "\n",
        "date de modification : 26/01/2023 16h\n",
        "\n",
        "NOM: VIN\n",
        "\n",
        "Prénom: Charles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TJrAm4JFr9V"
      },
      "source": [
        "Objectifs:\n",
        "Savoir organiser des données en pages pour permettre de modifier un tuple en ne modifiant qu'une seule page.\n",
        "\n",
        "Comprendre les méthodes d'accès suivantes :\n",
        "\n",
        "*   Lecture séquentielle d'une fichier : \"table access full\"\n",
        "*   Lecture d'un tuple dont on connait le rowid : \"table access by index rowid\"\n",
        "*   Opération de sélection par lecture séquentielle et filtrage \n",
        "\n",
        "Comprendre les méthodes d'indexation :\n",
        "\n",
        "*   Créer un index\n",
        "*   Opération de Sélection par index et lecture par rowid\n",
        "\n",
        "Mise à jour de données\n",
        "*   Sélectionner un tuple et modifier un de ses attributs\n",
        "*   Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n",
        "\n",
        "Persistence\n",
        "*   Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n",
        "*   Adapter en conséquence les opérations de modification de l'index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aodlGU01gLqK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil as sh\n",
        "import numpy as np\n",
        "import random\n",
        "from random import choice\n",
        "from string import ascii_lowercase\n",
        "import time\n",
        "\n",
        "DATA = \"data.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKX2fgx_gYT"
      },
      "source": [
        "# Générer un fichier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezxoKUCxtASX"
      },
      "source": [
        "Création du fichier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TIvmnhsTryK4"
      },
      "outputs": [],
      "source": [
        "# nb_lines = 5 * 1000 * 1000\n",
        "nb_lines = 10000\n",
        "nb_attributes = 7\n",
        "longueur_attribut = 100\n",
        "nb_valeurs_distinctes = nb_lines\n",
        "try:\n",
        "  open(DATA, \"r\")\n",
        "except FileNotFoundError:\n",
        "  # dure environ 40s pour 5M lignes\n",
        "  # string_val = \"\".join(choice(ascii_lowercase) for i in range(longueur_attribut))\n",
        "  long_string = ''.join('-' for i in range(longueur_attribut))\n",
        "\n",
        "  # a=[np.random.randint(0, int(nb_lines/(10**i)), nb_lines) for i in range(nb_attributes)]\n",
        "\n",
        "  # le premier attribut est unique\n",
        "  a = [random.sample(range(nb_valeurs_distinctes), nb_lines)]\n",
        "\n",
        "  # les attributs suivants ont des domaines plus petits\n",
        "  for i in range(1, nb_attributes):\n",
        "    nb_valeurs_distinctes = max(2, int(nb_valeurs_distinctes / 2))\n",
        "    a.append(np.random.randint(0, nb_valeurs_distinctes, nb_lines))\n",
        "\n",
        "  b = [ ','.join(map(lambda x: str(x), e)) + f\",{long_string}\\n\" for e in zip(*a)]\n",
        "\n",
        "  with open(DATA, \"w\") as f:\n",
        "    f.write(''.join(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1aMC3Y6yryK-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "head : \n",
            "5191,356,504,875,319,132,83,----------------------------------------------------------------------------------------------------\n",
            "8636,1548,791,155,471,291,102,----------------------------------------------------------------------------------------------------\n",
            "tail : \n",
            "7945,4972,410,1083,141,78,42,----------------------------------------------------------------------------------------------------\n",
            "1802,1159,956,811,541,81,8,----------------------------------------------------------------------------------------------------\n",
            "size (lines) :\n",
            "10000 data.csv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "echo \"head : \"\n",
        "head -n 2 data.csv\n",
        "echo \"tail : \"\n",
        "tail -n 2 data.csv\n",
        "echo \"size (lines) :\"\n",
        "wc -l data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gm8_3CY_odp"
      },
      "source": [
        "# Lecture séquentielle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nSX2XxLx_tBa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 530\n",
            "ligne 3441 : 530,2486,1470,56,224,96,42,----------------------------------------------------------------------------------------------------\n",
            "done in 0.01744675636291504 s\n"
          ]
        }
      ],
      "source": [
        "def filtrer_fichier(fichier, valeur_recherchee):\n",
        "  with open(fichier, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "      a = int(line.split(',')[0])\n",
        "      if a == s :\n",
        "        print(f\"ligne {i} :\", line.strip())\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_fichier(DATA, s)\n",
        "print(\"done in\", time.time() - t1, \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlmFE3aZTBWC"
      },
      "source": [
        "# Découper le fichier en pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kOEddKG8PHDF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pages dans : data_pages\n",
            "nb pages créées : 10\n"
          ]
        }
      ],
      "source": [
        "def page_dir_name(fichier):\n",
        "  return fichier.split('.')[0] + \"_pages\"\n",
        "\n",
        "def decoupe_fichier_en_pages(fichier, nb_tuple_par_page):\n",
        "  page_dir = page_dir_name(fichier)\n",
        "  print(\"pages dans :\", page_dir)\n",
        "  if(os.path.exists(page_dir)):\n",
        "    sh.rmtree(page_dir)\n",
        "  os.makedirs(page_dir, exist_ok=True)\n",
        "\n",
        "  with open(fichier, \"r\") as f:\n",
        "    p=0\n",
        "    lines = []\n",
        "    for i, line in enumerate(f):\n",
        "      lines.append(line)\n",
        "      if (i+1) % nb_tuple_par_page == 0:\n",
        "        p += 1\n",
        "        with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "          fp.write(''.join(lines))\n",
        "        lines = []\n",
        "    if len(lines) > 0:\n",
        "      p +=1\n",
        "      with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "          fp.write(''.join(lines))\n",
        "    \n",
        "    print(\"nb pages créées :\", p)\n",
        "\n",
        "decoupe_fichier_en_pages(DATA, nb_tuple_par_page=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqaml72_bXkj"
      },
      "source": [
        "Afficher le nombre de tuples dans une page (pour quelques pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qEX48QWEClJD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1000 data_pages/page1\n",
            "   1000 data_pages/page10\n",
            "   1000 data_pages/page2\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "wc -l data_pages/* | head -n 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4XDZAmbcUQb"
      },
      "source": [
        "# Lecture séquentielle du fichier découpé en pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fPVOrVpKccUG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 7702\n",
            "Research started\n",
            "Page n°2, Line n°299 : ('7702', '505', '413', '924', '112', '183', '149', '----------------------------------------------------------------------------------------------------\\n')\n",
            "done in 0.03 s\n"
          ]
        }
      ],
      "source": [
        "def lecture_sequentielle_par_page(fichier):\n",
        "#   # a faire : pour chaque page, lire ses lignes\n",
        "#   # une ligne devient un tuple\n",
        "#   # retourner un itérateur contenant le numéro de page, la position dans la page et le tuple\n",
        "    page_dir = page_dir_name(fichier)\n",
        "    nb_pages = len(os.listdir(page_dir))\n",
        "    for page_nb in range(1, nb_pages+1):\n",
        "        with open(page_dir + \"/page\" + str(page_nb), \"r\") as page:\n",
        "            for i, line in enumerate(page):\n",
        "                yield [page_nb, i, tuple(line.split(\",\"))]\n",
        "\n",
        "\n",
        "def filtrer_fichier_par_pages(fichier, valeur_recherchee):\n",
        "    l = lecture_sequentielle_par_page(fichier)\n",
        "    print('Research started')\n",
        "    for page_nb, pos_page, line in l:\n",
        "        if int(line[0]) == valeur_recherchee:\n",
        "            print(f\"Page n°{page_nb}, Line n°{pos_page} :\", line)\n",
        "\n",
        "#   # a faire pour chaque (numéro de page, position dans la page, tuple) obtnenu en invoquan la méthode ci dessus\n",
        "#   # convertir le 1er attribut en un nombre l'afficher si il est egal à la valeur recherchee\n",
        "\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_fichier_par_pages(DATA, s)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcmdLaQ5ruBJ"
      },
      "source": [
        "# Lecture d'un tuple dans une page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F4tYi4xCrxFG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'9440,3586,1428,940,116,55,152,----------------------------------------------------------------------------------------------------\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def lecture_tuple(fichier, num_page, position):\n",
        "    page_dir = page_dir_name(fichier)\n",
        "    with open(page_dir + '/page' + str(num_page), 'r') as page:\n",
        "        return page.readlines()[position]\n",
        "lecture_tuple(DATA, 1, 21)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mD_xZjLxXLD"
      },
      "source": [
        "# Créer un index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fhy4IJ0bxWHD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.07 s\n"
          ]
        }
      ],
      "source": [
        "def creation_index_unique(fichier):\n",
        "    index = {}\n",
        "    page_dir = page_dir_name(fichier)\n",
        "    nb_pages = len(os.listdir(page_dir))\n",
        "    for page_nb in range(1, nb_pages+1):\n",
        "        with open(page_dir + \"/page\" + str(page_nb), \"r\") as page:\n",
        "            for i, line in enumerate(page):\n",
        "                index[int(line.split(\",\")[0])] = (page_nb, i)\n",
        "    return index\n",
        "#    # la clé est la valeur du 1er attribut\n",
        "#    # la valeur est un rowid composé de (page, position)\n",
        "\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "index1 = creation_index_unique(DATA)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qA7hCef5Kfa"
      },
      "source": [
        "# Accès par index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0zrHPfGJjzm"
      },
      "source": [
        "## Index unique scan\n",
        "Accès pour rechercher les tuples dont le 1er attribut a une valeur donnée.\n",
        "\n",
        "On peut supposer pour simplifier que l'attribut est unique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PH3f5bz-5JTu"
      },
      "outputs": [],
      "source": [
        "def selection_par_index(fichier, valeur_recherchee):\n",
        "    index1 = creation_index_unique(DATA)\n",
        "    return index1[valeur_recherchee]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 299)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selection_par_index(DATA, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afvN2LWhJs0V"
      },
      "source": [
        "## Index range scan\n",
        "Accès pour rechercher les tuples dont le 1er attribut a une valeur comprise dans une intervalle donné"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EGEO1PheSEdT"
      },
      "outputs": [],
      "source": [
        "def selection_par_index_plage(fichier, borne_inf, borne_sup):\n",
        "    tuple_list = []\n",
        "    index = creation_index_unique(DATA)\n",
        "    for key in index.keys():\n",
        "        if borne_inf < key and key < borne_sup:\n",
        "            tuple_list.append(index[key])\n",
        "    return tuple_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UEKExgGfKRUs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 815), (6, 108), (7, 128), (7, 946)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selection_par_index_plage(DATA, 10, 15)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rjm99DrKR8t"
      },
      "source": [
        "# Mise à jour de données\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7np5NI8OKK6z"
      },
      "source": [
        "## Sélectionner un tuple et modifier un de ses attributs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCRwCGlwKlEK"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8zAZws5_KaL8"
      },
      "source": [
        "## Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_dcGN_dKaya"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as_W7xmOKc3l"
      },
      "source": [
        "# Persistence\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy8NE3x5KgLj"
      },
      "source": [
        "## Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqSClCOgKl6a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzDPXcGzKjKU"
      },
      "source": [
        "## Adapter en conséquence les opérations de modification de l'index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9mXqJeFKmUE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
