{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vZzLUr_l_Wfb"
      },
      "source": [
        "# TP 1 et 2 : Accès aux données avec index \n",
        "SAM, sujet pour étudiants\n",
        "\n",
        "date de modification : 01/02/2023\n",
        "\n",
        "NOM: VIN\n",
        "\n",
        "Prénom: Charles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TJrAm4JFr9V"
      },
      "source": [
        "Objectifs:\n",
        "Savoir organiser des données en pages pour permettre de modifier un tuple en ne modifiant qu'une seule page.\n",
        "\n",
        "Comprendre les méthodes d'accès suivantes :\n",
        "\n",
        "*   Lecture séquentielle d'une fichier : \"table access full\"\n",
        "*   Lecture d'un tuple dont on connait le rowid : \"table access by index rowid\"\n",
        "*   Opération de sélection par lecture séquentielle et filtrage \n",
        "\n",
        "Comprendre les méthodes d'indexation :\n",
        "\n",
        "*   Créer un index\n",
        "*   Opération de Sélection par index et lecture par rowid\n",
        "\n",
        "Mise à jour de données\n",
        "*   Sélectionner un tuple et modifier un de ses attributs\n",
        "*   Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n",
        "\n",
        "Persistence\n",
        "*   Stocker un index (dans plusieurs pages) pour le reconstruire plus rapidement\n",
        "*   Adapter en conséquence les opérations de modification de l'index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aodlGU01gLqK",
        "outputId": "bf2e77d6-9818-44f9-c296-38797c7a49ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nom de la table : T\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil as sh\n",
        "import numpy as np\n",
        "import random\n",
        "from random import choice\n",
        "from string import ascii_lowercase\n",
        "import time\n",
        "\n",
        "# le nom de la table \n",
        "TABLE = \"T\"\n",
        "print(\"nom de la table :\", TABLE)\n",
        "\n",
        "\n",
        "# le nom du fichier qui contient les données de la table\n",
        "def nom_fichier(table):\n",
        "    return table + \".csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKX2fgx_gYT"
      },
      "source": [
        "# Générer un fichier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezxoKUCxtASX"
      },
      "source": [
        "Création du fichier contenant un exemple de données.\n",
        "Ce sont des données au format csv. On suppose que chaque ligne correspond à un tuple d'une table **T** ayant *n* attributs :\n",
        "\n",
        "$$ T (a_0, a_1, a_2, ..., a_{n-1})$$\n",
        "\n",
        "Le premier attribut $a_0$ est unique\n",
        "\n",
        "Les attributs suivants ne sont pas uniques (ils ont des doublons). Pour l'attribut $a_1$, il y a en moyenne 2 tuples par valeur, pour $a_2$ il y a en moyenne 4 tuples par valeurs, etc. \n",
        "\n",
        "Les attributs sont des nombres entiers sauf le dernier qui est une chaine de caractères.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIvmnhsTryK4",
        "outputId": "d2657554-d88b-4f0c-bc82-0868273c4ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "données créées dans le fichier : T.csv\n"
          ]
        }
      ],
      "source": [
        "# dure environ 40s pour 5M lignes\n",
        "\n",
        "nb_lines = 5 * 1001 # * 1000\n",
        "nb_attributes = 7\n",
        "\n",
        "longueur_dernier_attribut = 100\n",
        "# attribut_chaine_caracteres = \"\".join(choice(ascii_lowercase) for i in range(longueur_dernier_attribut))\n",
        "attribut_chaine_caracteres = ''.join('-' for i in range(longueur_dernier_attribut))\n",
        "# print(\"le dernier attribut de chaque tuple est la chaine de caracètes :\", attribut_chaine_caracteres)\n",
        "\n",
        "nb_valeurs_distinctes = nb_lines\n",
        "\n",
        "\n",
        "# le premier attribut est unique\n",
        "a = [random.sample(range(nb_valeurs_distinctes), nb_lines)]\n",
        "\n",
        "# les attributs suivants ont des domaines plus petits\n",
        "for i in range(1, nb_attributes):\n",
        "  nb_valeurs_distinctes = max(2, int(nb_valeurs_distinctes / 2))\n",
        "  a.append(np.random.randint(0, nb_valeurs_distinctes, nb_lines))\n",
        "\n",
        "# on concatène \"verticalement\" les colonnes pour former les tuples.\n",
        "# Le dernier attribut est une chaine de caractères\n",
        "b = [ ','.join(map(lambda x: str(x), e)) + f\",{attribut_chaine_caracteres}\\n\" for e in zip(*a)]\n",
        "\n",
        "# on stocke les données dans un fichier\n",
        "fichier = nom_fichier(TABLE)\n",
        "with open(fichier, \"w\") as f:\n",
        "  f.write(''.join(b))\n",
        "\n",
        "print(\"données créées dans le fichier :\", fichier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogkKxanaBHQF"
      },
      "source": [
        "On affiche le début et la fin du fichier et son nombre de lignes ( = card(T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aMC3Y6yryK-",
        "outputId": "828ade35-bf19-4404-f8ef-3738e7e03dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "debut de T.csv :\n",
            "4073,196,814,503,43,69,62,----------------------------------------------------------------------------------------------------\n",
            "1468,1629,572,587,100,74,70,----------------------------------------------------------------------------------------------------\n",
            "\n",
            "fin de T.csv : \n",
            "2561,1641,952,299,93,105,68,----------------------------------------------------------------------------------------------------\n",
            "3877,1278,1160,219,165,101,67,----------------------------------------------------------------------------------------------------\n",
            "\n",
            "size (lines) :\n",
            "5005 T.csv\n"
          ]
        }
      ],
      "source": [
        "%%bash -s \"$fichier\"\n",
        "echo \"debut de $1 :\"\n",
        "head -n 2 $1\n",
        "echo\n",
        "echo \"fin de $1 : \"\n",
        "tail -n 2 $1\n",
        "echo\n",
        "echo \"size (lines) :\"\n",
        "wc -l $1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gm8_3CY_odp"
      },
      "source": [
        "# Lecture séquentielle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZaYoqeiHO2p"
      },
      "source": [
        "On définit un *iterateur* pour lire séquentiellement chaque ligne de la table stockée entièrement dans un seul fichier. Le mot python *yield* facilite la définition d'un itérateur.\n",
        "\n",
        "Cet itérateur est invoqué pour lire la table et appliquer un filtre.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSX2XxLx_tBa",
        "outputId": "1cd4779c-7314-4b62-eef1-32c0509bb89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 42\n",
            "ligne 4531 : 42,1215,634,405,210,93,49,----------------------------------------------------------------------------------------------------\n",
            "done in 0.024 s\n"
          ]
        }
      ],
      "source": [
        "def lecture_sequentielle(table):\n",
        "  fichier = nom_fichier(table)\n",
        "  with open(fichier, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "      yield i, line\n",
        "\n",
        "def filtrer_table(table, valeur_recherchee):\n",
        "  for i, line in lecture_sequentielle(table):\n",
        "      a = int(line.split(',')[0])\n",
        "      if a == valeur_recherchee :\n",
        "        print(f\"ligne {i} :\", line.strip())\n",
        "\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_table(TABLE, s)\n",
        "print(\"done in\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlmFE3aZTBWC"
      },
      "source": [
        "# Découper une table en pages\n",
        "\n",
        "On organise les données en pages. \n",
        "Pour faciliter le TP, chaque page est représentée par un \"petit\" fichier mais en réalité une page serait un bloc d'un fichier.\n",
        "\n",
        "Dans la suite du TP, on accédera toujours aux pages.\n",
        "Le fichier créé initialement, contenant tous les tuples, ne sera plus utilisé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOEddKG8PHDF",
        "outputId": "5e63ab9b-7eb8-4741-bc3c-2959cb820ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "les pages sont stockées dans le dossier T_pages\n",
            "nb pages créées : 6\n"
          ]
        }
      ],
      "source": [
        "def page_dir_name(table):\n",
        "  return table + \"_pages\"\n",
        "\n",
        "print(\"les pages sont stockées dans le dossier\", page_dir_name(TABLE) )\n",
        "\n",
        "def decoupe_table_en_pages(table, nb_tuple_par_page):\n",
        "  page_dir = page_dir_name(table)\n",
        "\n",
        "  # vider le dossier qui contiendra les pages\n",
        "  if(os.path.exists(page_dir)):\n",
        "    sh.rmtree(page_dir)\n",
        "  os.makedirs(page_dir, exist_ok=True)\n",
        "\n",
        "  # lire le fichier contenant tous les tuples\n",
        "  p=0\n",
        "  lines = []\n",
        "  for i, line in lecture_sequentielle(table):\n",
        "    lines.append(line)\n",
        "    if (i+1) % nb_tuple_par_page == 0:\n",
        "      \n",
        "      # créer une page\n",
        "      p += 1\n",
        "      with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "      lines = []\n",
        "\n",
        "  # créer une dernière page, si nécessaire\n",
        "  if len(lines) > 0:\n",
        "    p +=1\n",
        "    with open(page_dir + f\"/page{p}\", \"w\") as fp:\n",
        "        fp.write(''.join(lines))\n",
        "\n",
        "  print(\"nb pages créées :\", p)\n",
        "\n",
        "\n",
        "decoupe_table_en_pages(TABLE, nb_tuple_par_page=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqaml72_bXkj"
      },
      "source": [
        "Afficher le nombre de tuples dans une page (pour quelques pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEX48QWEClJD",
        "outputId": "6e329731-4ac9-4030-ec24-4fb32097692b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1000 T_pages/page1\n",
            "  1000 T_pages/page2\n",
            "  1000 T_pages/page3\n"
          ]
        }
      ],
      "source": [
        "%%bash -s \"$TABLE\"\n",
        "wc -l $1_pages/* | head -n 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4XDZAmbcUQb"
      },
      "source": [
        "# Lecture séquentielle d'une table découpée en pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "fPVOrVpKccUG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 57\n",
            "Research started\n",
            "Page n°3, Line n°369 : ('57', '428', '557', '415', '204', '49', '0', '----------------------------------------------------------------------------------------------------\\n')\n",
            "done in 0.03 s\n"
          ]
        }
      ],
      "source": [
        "def lecture_sequentielle_par_page(fichier):\n",
        "#   # a faire : pour chaque page, lire ses lignes\n",
        "#   # une ligne devient un tuple\n",
        "#   # retourner un itérateur contenant le numéro de page, la position dans la page et le tuple\n",
        "    page_dir = page_dir_name(fichier)\n",
        "    nb_pages = len(os.listdir(page_dir))\n",
        "    for page_nb in range(1, nb_pages+1):\n",
        "        with open(page_dir + \"/page\" + str(page_nb), \"r\") as page:\n",
        "            for i, line in enumerate(page):\n",
        "                yield [page_nb, i, tuple(line.split(\",\"))]\n",
        "\n",
        "\n",
        "def filtrer_fichier_par_pages(fichier, valeur_recherchee):\n",
        "    l = lecture_sequentielle_par_page(fichier)\n",
        "    print('Research started')\n",
        "    for page_nb, pos_page, line in l:\n",
        "        if int(line[0]) == valeur_recherchee:\n",
        "            print(f\"Page n°{page_nb}, Line n°{pos_page} :\", line)\n",
        "\n",
        "#   # a faire pour chaque (numéro de page, position dans la page, tuple) obtnenu en invoquan la méthode ci dessus\n",
        "#   # convertir le 1er attribut en un nombre l'afficher si il est egal à la valeur recherchee\n",
        "\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "filtrer_fichier_par_pages(TABLE, s)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcmdLaQ5ruBJ"
      },
      "source": [
        "# Lecture d'un tuple dans une page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow_RkbQ_U8qs"
      },
      "source": [
        "Cette fonction retourne un tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "F4tYi4xCrxFG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4389,1310,478,50,167,29,29,----------------------------------------------------------------------------------------------------\n",
            "\n",
            "done in 3.0 ms\n"
          ]
        }
      ],
      "source": [
        "def lecture_tuple(table, num_page, position):\n",
        "    page_dir = page_dir_name(table)\n",
        "    with open(page_dir + '/page' + str(num_page), 'r') as page:\n",
        "        return page.readlines()[position]\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "print(lecture_tuple(TABLE, 3, 456))\n",
        "print(\"done in\", round((time.time() - t1)*1000, 1), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mD_xZjLxXLD"
      },
      "source": [
        "# Créer un index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNgxRQtOTwOH"
      },
      "source": [
        "## Créer un index unique pour l'attribut $a_0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCJyftyiXyFo"
      },
      "source": [
        "On sait que $a_0$ est unique. \n",
        "Une entrée associe une *clé* à une *valeur*.\n",
        "*   La *clé* est la valeur du 1er attribut. \n",
        "*   La *valeur* est un **rowid** formé des informations (page, position)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Fhy4IJ0bxWHD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.01 s\n"
          ]
        }
      ],
      "source": [
        "def creation_index_unique(table):\n",
        "    index = {}\n",
        "    page_dir = page_dir_name(table)\n",
        "    nb_pages = len(os.listdir(page_dir))\n",
        "    for page_nb in range(1, nb_pages+1):\n",
        "        with open(page_dir + \"/page\" + str(page_nb), \"r\") as page:\n",
        "            for i, line in enumerate(page):\n",
        "                index[int(line.split(\",\")[0])] = (page_nb, i)\n",
        "    return index\n",
        "#    # la clé est la valeur du 1er attribut\n",
        "#    # la valeur est un rowid composé de (page, position)\n",
        "\n",
        "t1 = time.time()\n",
        "INDEX_UNIQUE_a0 = creation_index_unique(TABLE)\n",
        "print(\"done in\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "r1H4RAlCvBA3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12 (2, 517)\n"
          ]
        }
      ],
      "source": [
        "# vérifier l'index unique\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(s, INDEX_UNIQUE_a0[s])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcUQ8XRcT1dg"
      },
      "source": [
        "## Créer un index non unique pour l'attribut $a_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4AtpJouWSmB"
      },
      "source": [
        "On donne un nom de table et le numéro $i$ de l'attribut $a_i$ de la table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "gxJC1-m-VRC5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.016 s\n"
          ]
        }
      ],
      "source": [
        "def creation_index(table, numero_attribut):\n",
        "    index = {}\n",
        "    page_dir = page_dir_name(table)\n",
        "    nb_pages = len(os.listdir(page_dir))\n",
        "    for page_nb in range(1, nb_pages+1):\n",
        "        with open(page_dir + \"/page\" + str(page_nb), \"r\") as page:\n",
        "            for i, line in enumerate(page):\n",
        "                try:\n",
        "                    index[int(line.split(\",\")[numero_attribut])].append((page_nb, i))\n",
        "                except KeyError:\n",
        "                    index[int(line.split(\",\")[numero_attribut])] = [(page_nb, i)]\n",
        "    return index\n",
        "    # la clé est la valeur du 1er attribut <= ???? Du premier ou du ième ??  \n",
        "    # la valeur est une *liste* de rowid\n",
        "\n",
        "t1 = time.time()\n",
        "INDEX_a2 = creation_index(TABLE, 2)\n",
        "print(\"done in\", round(time.time() - t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "Jd4PJ75JvESP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 0\n",
            "(1, 328)\n",
            "(1, 873)\n",
            "(2, 374)\n",
            "(2, 654)\n",
            "(2, 812)\n",
            "(3, 622)\n",
            "(3, 932)\n",
            "(4, 232)\n",
            "(5, 168)\n"
          ]
        }
      ],
      "source": [
        "# vérifier l'index\n",
        "s = np.random.randint(nb_valeurs_distinctes/4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "for r in INDEX_a2[s]:\n",
        "    print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qA7hCef5Kfa"
      },
      "source": [
        "# Accès par index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0zrHPfGJjzm"
      },
      "source": [
        "## Accès ciblé \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EEEUaCYqhIaB"
      },
      "source": [
        "### Index unique scan. \n",
        "Accès pour rechercher le tuple dont l'attribut indexé a une valeur donnée (on suppose que l'attribut est unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "PH3f5bz-5JTu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 42\n",
            "done in 0.42 ms\n"
          ]
        }
      ],
      "source": [
        "def acces_par_index_unique(index_unique, table, valeur_recherchee):\n",
        "    return index_unique.get(valeur_recherchee, None)\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "acces_par_index_unique(INDEX_UNIQUE_a0, TABLE, s)\n",
        "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xfR_0QAShCJi"
      },
      "source": [
        "### Index scan\n",
        "Accès pour rechercher les tuples dont l'attribut indexé a une valeur donnée. On suppose que l'attribut n'est pas unique et que plusieurs tuples sont retrouvés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "4eyjynk_hZer"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 31\n",
            "done in 0.22 ms\n"
          ]
        }
      ],
      "source": [
        "def acces_par_index(index, table, valeur_recherchee):\n",
        "    return index.get(valeur_recherchee, None)\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "acces_par_index(INDEX_UNIQUE_a0, TABLE, s)\n",
        "print(\"done in\", round((time.time() - t1)*1000, 2), \"ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afvN2LWhJs0V"
      },
      "source": [
        "## Accès par intervalle \n",
        "Index range scan\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIL6jrUuaPMO"
      },
      "source": [
        "### Accès par intervalle sur un attribut unique\n",
        "Accès pour rechercher les tuples dont l'attribut indexé est unique et a une valeur comprise dans un intervalle donné."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "EGEO1PheSEdT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 6\n",
            "done in 0.0 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(1, 8), (2, 517), (3, 439), (3, 472)]"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def acces_intervalle_par_index_unique(index_unique, table, fichier, borne_inf, borne_sup):\n",
        "    tuple_list = []\n",
        "    for key in index_unique.keys():\n",
        "        if borne_inf < key and key < borne_sup:\n",
        "            tuple_list.append(index_unique[key])\n",
        "    return tuple_list\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes/4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "acces_intervalle_par_index_unique(INDEX_UNIQUE_a0, TABLE, s, 10, 15)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")\n",
        "acces_intervalle_par_index_unique(INDEX_UNIQUE_a0, TABLE, s, 10, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDaG7WelaQrG"
      },
      "source": [
        "### Accès par intervalle sur un attribut NON unique\n",
        "Accès pour rechercher les tuples dont l'attribut indexé n'est **pas** unique et a une valeur comprise dans un intervalle donné."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "KQEYfcoEak5A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valeur recherchée : 3\n",
            "done in 0.0 s\n"
          ]
        }
      ],
      "source": [
        "def acces_intervalle_par_index(index, table, fichier, borne_inf, borne_sup):\n",
        "    tuple_list = []\n",
        "    for key in index.keys():\n",
        "        if borne_inf < key and key < borne_sup:\n",
        "            for rowid in index[key]:\n",
        "                tuple_list.append(rowid)\n",
        "    return tuple_list\n",
        "\n",
        "\n",
        "\n",
        "s = np.random.randint(nb_valeurs_distinctes / 4)\n",
        "print(\"valeur recherchée :\", s)\n",
        "\n",
        "t1 = time.time()\n",
        "acces_intervalle_par_index(INDEX_a2, TABLE, s, 10, 15)\n",
        "print(\"done in\", round(time.time() - t1, 2), \"s\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rjm99DrKR8t"
      },
      "source": [
        "# Mise à jour de données\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7np5NI8OKK6z"
      },
      "source": [
        "## Sélectionner un tuple et modifier un de ses attributs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7aN87BOuEbq"
      },
      "source": [
        "### Modification d'un seul tuple\n",
        "\n",
        "On donne une valeur *v* de l'attribut clé $a_0$. Ajouter 1 à l'attribut $a_1$. Cela correspond à l'instruction\n",
        "\n",
        "update T\n",
        "set a1 = a1+1\n",
        "where a0 = *v*\n",
        "\n",
        "Après la modification, accéder aux données pour vérifier que le tuple a bien été modifié. Par exemple, invoquer la fonction\n",
        "acces_par_index_unique(index, table, v)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "RCRwCGlwKlEK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ancienne valeur : 1774\n",
            "Nouvelle valeur : 1775\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2, 385)"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def ecriture_tuple(table, num_page, position, attribut, new_valeur):\n",
        "    page_dir = page_dir_name(table)\n",
        "    with open(page_dir + '/page' + str(num_page), 'r+') as page:\n",
        "        lines = page.readlines()\n",
        "        splited_line = lines[position].split(',')\n",
        "        splited_line[attribut] = str(new_valeur)\n",
        "        lines[position] = ','.join(splited_line)\n",
        "        page.seek(0)\n",
        "        page.writelines(lines) # Du coup on réécrit tout le fichier à chaque fois :/ \n",
        "    return True\n",
        "\n",
        "def incremente(index, table, v):\n",
        "    num_page, position = index[v]\n",
        "    \n",
        "    old_val = lecture_tuple(table, num_page, position).split(',')[1]\n",
        "    print(f'Ancienne valeur : {old_val}')\n",
        "    \n",
        "    ecriture_tuple(table, num_page, position, 1, int(old_val)+1)\n",
        "\n",
        "    new_val = lecture_tuple(table, num_page, position).split(',')[1]\n",
        "    print(f'Nouvelle valeur : {new_val}')\n",
        "    \n",
        "incremente(INDEX_UNIQUE_a0, TABLE, s)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"color: red\">PROBLEME ICI</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdexpmRuKfs2"
      },
      "source": [
        "### Modification de plusieurs tuples\n",
        "\n",
        "On donne une valeur *v* de l'attribut $a_2$ qui n'est pas unique. Ajouter 1 à l'attribut $a_3$.\n",
        "\n",
        "update T set a3 = a3+1 where a1=v\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "J_18vhvxM61d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ancienne valeur : 2482\n",
            "Nouvelle valeur : 2483\n",
            "Ancienne valeur : 130\n",
            "Nouvelle valeur : 131\n",
            "Ancienne valeur : 1167\n",
            "Nouvelle valeur : 1168\n",
            "Ancienne valeur : 1873\n",
            "Nouvelle valeur : 1874\n",
            "Ancienne valeur : 1606\n",
            "Nouvelle valeur : 1607\n",
            "Ancienne valeur : 2279\n",
            "Nouvelle valeur : 2280\n"
          ]
        }
      ],
      "source": [
        "def ecriture_tuple(table, num_page, position, attribut, new_valeur):\n",
        "    page_dir = page_dir_name(table)\n",
        "    with open(page_dir + '/page' + str(num_page), 'r+') as page:\n",
        "        lines = page.readlines()\n",
        "        splited_line = lines[position].split(',')\n",
        "        splited_line[attribut] = str(new_valeur)\n",
        "        lines[position] = ','.join(splited_line)\n",
        "        page.seek(0)\n",
        "        page.writelines(lines) # Du coup on réécrit tout le fichier à chaque fois :/ \n",
        "    return True\n",
        "\n",
        "def incremente(index, table, v):\n",
        "    for num_page, position in index[v]:\n",
        "        old_val = lecture_tuple(table, num_page, position).split(',')[1]\n",
        "        print(f'Ancienne valeur : {old_val}')\n",
        "        \n",
        "        ecriture_tuple(table, num_page, position, 1, int(old_val)+1)\n",
        "\n",
        "        new_val = lecture_tuple(table, num_page, position).split(',')[1]\n",
        "        print(f'Nouvelle valeur : {new_val}')\n",
        "    \n",
        "incremente(INDEX_a2, TABLE, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zAZws5_KaL8"
      },
      "source": [
        "## Modifier l'index en conséquence lorsque l'attibut modifié est indexé\n",
        "Par exemple, si $a_3$ est indexé, la mise à jour de la question précédente implique d'actualiser l'index sur $a_3$  pour que les rowid associés à l'ancienne valeur de $a_3$  soient associés à la nouvelle valeur de $a_3$ ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "3_dcGN_dKaya"
      },
      "outputs": [],
      "source": [
        "def update_index(index, old_val, new_val):\n",
        "    value = index[old_val]\n",
        "    del index[old_val]\n",
        "    index[new_val] = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as_W7xmOKc3l"
      },
      "source": [
        "# Persistence\n",
        "\n",
        "Dans cette partie, on veut rendre les index persistents en les stockant dans des pages. Cela permet d'utiliser les index plus efficacement sans les recréer entièrement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy8NE3x5KgLj"
      },
      "source": [
        "## Stockage d'un index unique\n",
        "\n",
        "Proposer une solution pour stocker les entrées triées d'un index unique dans plusieurs pages avec une taille de page fixée (500 entrées par page,  soit 500 clés + 500 rowid)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "VqSClCOgKl6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def write_index_unique(index, table_name, nb_index_par_page=500):\n",
        "    index_dir = f\"{table_name}_index\"\n",
        "    if(os.path.exists(index_dir)):\n",
        "        sh.rmtree(index_dir)\n",
        "    os.makedirs(index_dir, exist_ok=True)\n",
        "\n",
        "    key_list = sorted(index.keys())\n",
        "    p = 1\n",
        "    f = open(index_dir + f\"/page{p}\", 'w')\n",
        "    for i, key in enumerate(key_list):\n",
        "        if (i+1) % nb_index_par_page == 0:\n",
        "            f.close()\n",
        "            f = open(index_dir + f\"/page{p}\", 'w')\n",
        "            p += 1\n",
        "        f.write(f'{str(key)},{str(index[key][0])},{str(index[key][1])} \\n')\n",
        "    else:\n",
        "        f.close()\n",
        "        return True\n",
        "write_index_unique(INDEX_UNIQUE_a0, TABLE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aKuhJaDloKO"
      },
      "source": [
        "## Stockage d'un index non unique\n",
        "Proposer une solution pour stocker les entrées triées d'un index non unique dans plusieurs pages avec une taille de page fixée. Dans une page, le total du nombre  de clés + le nombre de rowid ne peut pas dépasser 1000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def write_index_non_unique(index, table_name, nb_index_par_page=500):\n",
        "    index_dir = f\"{table_name}_index\"\n",
        "    if(os.path.exists(index_dir)):\n",
        "        sh.rmtree(index_dir)\n",
        "    os.makedirs(index_dir, exist_ok=True)\n",
        "\n",
        "    key_list = sorted(index.keys())\n",
        "    p = 1\n",
        "    i = 0\n",
        "    f = open(index_dir + f\"/page{p}\", 'w')\n",
        "    for key in key_list:\n",
        "        for rowid in index[key]:\n",
        "            if (i+1) % nb_index_par_page == 0:\n",
        "                f.close()\n",
        "                f = open(index_dir + f\"/page{p}\", 'w')\n",
        "                p += 1\n",
        "            f.write(f'{str(key)},{str(rowid[0])},{str(rowid[1])} \\n')\n",
        "            i += 1\n",
        "    else:\n",
        "        f.close()\n",
        "        return True\n",
        "write_index_non_unique(INDEX_a2, TABLE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzDPXcGzKjKU"
      },
      "source": [
        "## Adapter en conséquence les opérations de modification de l'index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9mXqJeFKmUE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYiNNktwEQsr"
      },
      "source": [
        "# Questions facultatives\n",
        "\n",
        "## Index bitmap\n",
        "*   Proposer un index ayant une structure \"bitmap\" pour l'attribut $a_5$. Idem pour l'attribut $a_6$. \n",
        "*   En utilisant les 2 index bitmap, rechercher les tuples de T tels que $a_5 = v_1$ et $a_6 = v_2$ pour deux valeurs $v_1, v_2$ appartenant au domaine de $a_5 \\cap a_6$ .\n",
        "\n",
        "## Index couvrant une requête\n",
        "* Illustrer les cas vus en TD.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
